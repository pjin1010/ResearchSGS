{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9eea383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterjin/opt/anaconda3/lib/python3.9/site-packages/xarray/backends/cfgrib_.py:27: UserWarning: Failed to load cfgrib - most likely there is a problem accessing the ecCodes library. Try `import cfgrib` to get the full error message\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pyqg\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import grad, Variable\n",
    "%run utils.ipynb\n",
    "%run WDL.ipynb\n",
    "\n",
    "class FullyCNN_w(nn.Sequential):\n",
    "    \"\"\"Pytorch class defining our CNN architecture, plus some helpers for\n",
    "    dealing with constraints and scaling.\"\"\"\n",
    "    def __init__(self, inputs, targets, padding='circular', zero_mean=True):\n",
    "        if padding is None:\n",
    "            padding_5 = 0\n",
    "            padding_3 = 0\n",
    "        elif padding in ['same', 'circular']:\n",
    "            padding_5 = 2\n",
    "            padding_3 = 1\n",
    "        else:\n",
    "            raise ValueError('Unknown value for padding parameter.')\n",
    "        self.padding = padding\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "        n_in = len(inputs)\n",
    "        n_out = len(targets)\n",
    "        self.n_in = n_in\n",
    "        kw = {}\n",
    "        if padding == 'circular':\n",
    "            kw['padding_mode'] = 'circular'\n",
    "        block1 = self._make_subblock(nn.Conv2d(n_in, 128, 5, padding=padding_5, **kw))\n",
    "        block2 = self._make_subblock(nn.Conv2d(128, 64, 5, padding=padding_5, **kw))\n",
    "        block3 = self._make_subblock(nn.Conv2d(64, 32, 3, padding=padding_3, **kw))\n",
    "        block4 = self._make_subblock(nn.Conv2d(32, 32, 3, padding=padding_3, **kw))\n",
    "        block5 = self._make_subblock(nn.Conv2d(32, 32, 3, padding=padding_3, **kw))\n",
    "        block6 = self._make_subblock(nn.Conv2d(32, 32, 3, padding=padding_3, **kw))\n",
    "        block7 = self._make_subblock(nn.Conv2d(32, 32, 3, padding=padding_3, **kw))\n",
    "        conv8 = nn.Conv2d(32, n_out, 3, padding=padding_3)\n",
    "        super().__init__(*block1, *block2, *block3, *block4, *block5,\n",
    "                            *block6, *block7, conv8)\n",
    "        self.is_zero_mean = zero_mean\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = super().forward(x)\n",
    "        if self.is_zero_mean:\n",
    "            return r - r.mean(dim=(1,2,3), keepdim=True)\n",
    "        else:\n",
    "            return r\n",
    "        \n",
    "    def _make_subblock(self, conv):\n",
    "        return [conv, nn.ReLU(), nn.BatchNorm2d(conv.out_channels)]\n",
    "\n",
    "    def extract_vars(self, m, features, dtype=np.float32):\n",
    "        ex = FeatureExtractor(m)\n",
    "\n",
    "        arr = np.stack([\n",
    "            np.take(ex(feat), z, axis=-3) for feat, z in features\n",
    "        ], axis=-3)\n",
    "\n",
    "        arr = arr.reshape((-1, len(features), ex.nx, ex.nx))\n",
    "        arr = arr.astype(dtype)\n",
    "        return arr\n",
    "\n",
    "    def extract_inputs(self, m):\n",
    "        return self.extract_vars(m, self.inputs)\n",
    "\n",
    "    def extract_targets(self, m):\n",
    "        return self.extract_vars(m, self.targets)\n",
    "\n",
    "    def input_gradients(self, inputs, output_channel, j, i, device=None):\n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.to(device)\n",
    "\n",
    "        X = self.input_scale.transform(self.extract_inputs(inputs))\n",
    "\n",
    "        grads = []\n",
    "        for x_, in minibatch(X, shuffle=False, as_tensor=False):\n",
    "            x = Variable(torch.tensor(x_), requires_grad=True).to(device)\n",
    "            y = self.forward(x)[:,output_channel,j,i]\n",
    "            grads.append(grad(y.sum(), x)[0].cpu().numpy())\n",
    "\n",
    "        grads = self.output_scale.inverse_transform(np.vstack(grads))\n",
    "\n",
    "        s = list(inputs.q.shape)\n",
    "        grads = np.stack([\n",
    "            grads[:,i].reshape(s[:-3] + s[-2:])\n",
    "            for i in range(len(self.targets))\n",
    "        ], axis=-3)\n",
    "\n",
    "        if isinstance(inputs, pyqg.Model):\n",
    "            return grads.astype(inputs.q.dtype)\n",
    "        else:\n",
    "            return grads\n",
    "\n",
    "    def predict(self, inputs, device=None):\n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "            self.to(device)\n",
    "        \n",
    "        X = self.input_scale.transform(self.extract_inputs(inputs))\n",
    "\n",
    "        preds = []\n",
    "        for x, in minibatch(X, shuffle=False):\n",
    "            x = x.to(device)\n",
    "            with torch.no_grad():\n",
    "                preds.append(self.forward(x).cpu().numpy())\n",
    "                output = self.forward(x).cpu().numpy()\n",
    "                #print(output.shape)\n",
    "\n",
    "        preds = self.output_scale.inverse_transform(np.vstack(preds))\n",
    "\n",
    "        s = list(inputs.q.shape)\n",
    "        preds = np.stack([\n",
    "            preds[:,i].reshape(s[:-3] + s[-2:])\n",
    "            for i in range(len(self.targets))\n",
    "        ], axis=-3)\n",
    "\n",
    "        try:\n",
    "            return preds.astype(inputs.q.dtype)\n",
    "        except:\n",
    "            return preds\n",
    "\n",
    "    def mse(self, inputs, targets, **kw):\n",
    "        y_true = targets.reshape(-1, np.prod(targets.shape[1:]))\n",
    "        y_pred = self.predict(inputs).reshape(-1, np.prod(targets.shape[1:]))\n",
    "        return np.mean(np.sum((y_pred - y_true)**2, axis=1))\n",
    "\n",
    "    def fit(self, inputs, targets, rescale=False, **kw):\n",
    "        if rescale or not hasattr(self, 'input_scale') or self.input_scale is None:\n",
    "            self.input_scale = ChannelwiseScaler(inputs)\n",
    "        if rescale or not hasattr(self, 'output_scale') or self.output_scale is None:\n",
    "            self.output_scale = ChannelwiseScaler(targets, zero_mean=self.is_zero_mean)\n",
    "        train_w(self,\n",
    "              self.input_scale.transform(inputs),\n",
    "              self.output_scale.transform(targets),\n",
    "              **kw)\n",
    "\n",
    "    def save(self, path):\n",
    "        os.system(f\"mkdir -p {path}\")\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.cpu()\n",
    "        torch.save(self.state_dict(), f\"{path}/weights.pt\")\n",
    "        self.to(device)\n",
    "        if hasattr(self, 'input_scale') and self.input_scale is not None:\n",
    "            with open(f\"{path}/input_scale.pkl\", 'wb') as f:\n",
    "                pickle.dump(self.input_scale, f)\n",
    "        if hasattr(self, 'output_scale')  and self.output_scale is not None:\n",
    "            with open(f\"{path}/output_scale.pkl\", 'wb') as f:\n",
    "                pickle.dump(self.output_scale, f)\n",
    "        with open(f\"{path}/inputs.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.inputs, f)\n",
    "        with open(f\"{path}/targets.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.targets, f)\n",
    "        if self.is_zero_mean:\n",
    "            open(f\"{path}/zero_mean\", 'a').close()\n",
    "        if hasattr(self, 'padding'):\n",
    "            with open(f\"{path}/padding\", 'w') as f:\n",
    "                f.write(self.padding)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path, set_eval=True, **kwargs):\n",
    "        with open(f\"{path}/inputs.pkl\", 'rb') as f:\n",
    "            inputs = pickle.load(f)\n",
    "        with open(f\"{path}/targets.pkl\", 'rb') as f:\n",
    "            targets = pickle.load(f)\n",
    "        kw = {}\n",
    "        kw.update(**kwargs)\n",
    "        if os.path.exists(f\"{path}/padding\"):\n",
    "            with open(f\"{path}/padding\", 'r') as f:\n",
    "                kw['padding'] = f.read().strip()\n",
    "        model = cls(inputs, targets, **kw)\n",
    "        model.load_state_dict(torch.load(f\"{path}/weights.pt\"))\n",
    "        if os.path.exists(f\"{path}/input_scale.pkl\"):\n",
    "            with open(f\"{path}/input_scale.pkl\", 'rb') as f:\n",
    "                model.input_scale = pickle.load(f)\n",
    "        if os.path.exists(f\"{path}/output_scale.pkl\"):\n",
    "            with open(f\"{path}/output_scale.pkl\", 'rb') as f:\n",
    "                model.output_scale = pickle.load(f)\n",
    "        if os.path.exists(f\"{path}/zero_mean\"):\n",
    "            model.is_zero_mean = True\n",
    "        if set_eval:\n",
    "            model.eval()\n",
    "        return model\n",
    "\n",
    "class BasicScaler(object):\n",
    "    def __init__(self, mu=0, sd=1):\n",
    "        self.mu = mu\n",
    "        self.sd = sd\n",
    "        \n",
    "    def transform(self, x):\n",
    "        return (x - self.mu) / self.sd\n",
    "    \n",
    "    def inverse_transform(self, z):\n",
    "        return z * self.sd + self.mu\n",
    "\n",
    "class ChannelwiseScaler(BasicScaler):\n",
    "    def __init__(self, x, zero_mean=False):\n",
    "        assert len(x.shape) == 4\n",
    "        if zero_mean:\n",
    "            mu = 0\n",
    "        else:\n",
    "            mu = np.array([x[:,i].mean()\n",
    "                for i in range(x.shape[1])])[np.newaxis,:,np.newaxis,np.newaxis]\n",
    "        sd = np.array([x[:,i].std()\n",
    "            for i in range(x.shape[1])])[np.newaxis,:,np.newaxis,np.newaxis]\n",
    "        super().__init__(mu, sd)\n",
    "\n",
    "def minibatch(*arrays, batch_size=64, as_tensor=True, shuffle=True):\n",
    "    assert len(set([len(a) for a in arrays])) == 1\n",
    "    order = np.arange(len(arrays[0]))\n",
    "    if shuffle:\n",
    "        np.random.shuffle(order)\n",
    "    steps = int(np.ceil(len(arrays[0]) / batch_size))\n",
    "    xform = torch.as_tensor if as_tensor else lambda x: x\n",
    "    for step in range(steps):\n",
    "        idx = order[step*batch_size:(step+1)*batch_size]\n",
    "        yield tuple(xform(array[idx]) for array in arrays)\n",
    "\n",
    "def train_w(net, inputs, targets, num_epochs=50, batch_size=64, learning_rate=0.001, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        net.to(device)\n",
    "    \n",
    "    #############################\n",
    "    \n",
    "    ### --- POINT ---\n",
    "    criterion_pt = nn.MSELoss()\n",
    "    \n",
    "    ### --- DISTRIBUTION ---\n",
    "    k = 3 # number of components in gmm\n",
    "    \n",
    "    n_levs = 100\n",
    "    q_vec = torch.arange(1, n_levs, dtype=torch.float64) / n_levs # quantile levels: 99\n",
    "   \n",
    "    alpha_matrix = torch.tensor(np.random.randn(1, k), requires_grad=True) #TODO: change the order/normalize\n",
    "    mu_matrix = torch.tensor(np.random.randn(1, k), requires_grad=True)\n",
    "    sd_matrix = torch.tensor(np.random.randn(1, k), requires_grad=True) # 4096x2\n",
    "    #############################\n",
    "    \n",
    "    optimizer_p = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    optimizer_d = optim.SGD([alpha_matrix, mu_matrix, sd_matrix], lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[int(num_epochs/2), int(num_epochs*3/4), int(num_epochs*7/8)], gamma=0.1)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "                    \n",
    "        for x, y in minibatch(inputs, targets, batch_size=batch_size):\n",
    "            optimizer_p.zero_grad()\n",
    "            ytrue = y.to(device)\n",
    "\n",
    "            # --- pointwise update ---\n",
    "            yhat = net.forward(x.to(device))\n",
    "            #print(yhat.shape)\n",
    "            #print(yhat)\n",
    "            #print(ytrue.shape)\n",
    "            loss_pt = criterion_pt(yhat, ytrue)\n",
    "            loss_pt.backward()\n",
    "            optimizer_p.step()\n",
    "            \n",
    "            # --- GMM update ---\n",
    "            ytrue = ytrue.squeeze()\n",
    "            yhat = yhat.squeeze()\n",
    "            \n",
    "            n_dist = ytrue.shape[0] # timesteps: 64\n",
    "            \n",
    "            # transform targets\n",
    "            Q_mat = np.array([np.quantile(ytrue[i].ravel(), q_vec) for i in range(n_dist)]) # calculate the empirical quantile function\n",
    "            y_train = torch.tensor(Q_mat) #[64, 99]\n",
    "            \n",
    "            for t in range(n_dist):\n",
    "                yhat_t = yhat[t].ravel().unsqueeze(dim=1).clone().detach()\n",
    "                \n",
    "                alpha = torch.matmul(yhat_t, alpha_matrix.float()) #[4096, 3]\n",
    "                mu = torch.matmul(yhat_t, mu_matrix.float()) #[4096, 3]\n",
    "                sd = torch.abs(torch.matmul(torch.abs(yhat_t), sd_matrix.float())) #[4096, 3]\n",
    "                pi = torch.softmax(alpha, dim=1) #[4096, 3]\n",
    "\n",
    "                optimizer_d.zero_grad()\n",
    "\n",
    "                #for t in range(0, mu.shape[0]):\n",
    "                loss_dist = WDL(y_train[t], q_vec, mu, sd, pi)\n",
    "                loss_dist.backward()\n",
    "    \n",
    "                optimizer_d.step()\n",
    "            #scheduler.step()\n",
    "            epoch_loss += loss_pt.item()\n",
    "            epoch_loss += loss_dist.item()\n",
    "            epoch_steps += 1\n",
    "        print(f\"Loss after Epoch {epoch+1}: {epoch_loss/epoch_steps}\")\n",
    "        scheduler.step()      \n",
    "        \n",
    "\n",
    "class FCNNParameterization_w(Parameterization):\n",
    "    def __init__(self, directory, models=None, **kw):\n",
    "        self.directory = directory\n",
    "        #print(sorted(glob.glob(os.path.join(directory, \"models/*\"))))\n",
    "        self.models = models if models is not None else [\n",
    "            FullyCNN_w.load(f, **kw)\n",
    "            for f in sorted(glob.glob(os.path.join(directory, \"models/*\")))\n",
    "        ]\n",
    "\n",
    "    @property\n",
    "    def targets(self):\n",
    "        targets = set()\n",
    "        for model in self.models:\n",
    "            for target, z in model.targets:\n",
    "                targets.add(target)\n",
    "        return list(sorted(list(targets)))\n",
    "\n",
    "    def predict(self, m):\n",
    "        preds = {}\n",
    "\n",
    "        for model in self.models:\n",
    "            pred = model.predict(m)\n",
    "            assert len(pred.shape) == len(m.q.shape)\n",
    "            # Handle the arduous task of getting the indices right for many\n",
    "            # possible input shapes (e.g. pyqg.Model or xr.Dataset snapshot\n",
    "            # stack)\n",
    "            for channel in range(pred.shape[-3]):\n",
    "                target, z = model.targets[channel]\n",
    "                if target not in preds:\n",
    "                    preds[target] = np.zeros_like(m.q)\n",
    "                out_indices = [slice(None) for _ in m.q.shape]\n",
    "                out_indices[-3] = slice(z,z+1)\n",
    "                in_indices = [slice(None) for _ in m.q.shape]\n",
    "                in_indices[-3] = slice(channel,channel+1)\n",
    "                preds[target][tuple(out_indices)] = pred[tuple(in_indices)]\n",
    "\n",
    "        return preds\n",
    "\n",
    "    @classmethod\n",
    "    def train_on(cls, dataset, directory,\n",
    "            inputs=['q','u','v'],\n",
    "            targets=['q_subgrid_forcing'],\n",
    "            num_epochs=50,\n",
    "            zero_mean=True,\n",
    "            padding='circular', **kw):\n",
    "\n",
    "        layers = range(len(dataset.lev))\n",
    "\n",
    "        models = [\n",
    "            FullyCNN_w(\n",
    "                [(feat, zi) for feat in inputs for zi in layers],\n",
    "                [(feat, z) for feat in targets],\n",
    "                zero_mean=zero_mean,\n",
    "                padding=padding\n",
    "\n",
    "            ) for z in layers\n",
    "        ]\n",
    "\n",
    "        # Train models on dataset and save them\n",
    "        trained = []\n",
    "        for z, model in enumerate(models):\n",
    "            model_dir = os.path.join(directory, f\"models/{z}\")\n",
    "            if os.path.exists(model_dir):\n",
    "                trained.append(FullyCNN_w.load(model_dir))\n",
    "            else:\n",
    "                X = model.extract_inputs(dataset)\n",
    "                Y = model.extract_targets(dataset)\n",
    "                model.fit(X, Y, num_epochs=num_epochs, **kw)\n",
    "                model.save(os.path.join(directory, f\"models/{z}\"))\n",
    "                trained.append(model)\n",
    "\n",
    "        # Return the trained parameterization\n",
    "        return cls(directory, models=trained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1762cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wdiff(ds1, ds2, T=10):\n",
    "    if 'run' not in ds1.dims: ds1 = ds1.expand_dims('run')\n",
    "    if 'run' not in ds2.dims: ds2 = ds2.expand_dims('run')\n",
    "\n",
    "    # Define our quantities using our feature extraction DSL. Note that some\n",
    "    # are off by a factor of 2 which does affect Wasserstein distance, but this\n",
    "    # isn't important for distributional similarity metrics since we normalize.\n",
    "    distribution_quantities = dict(\n",
    "        q='q',\n",
    "        u='ufull',\n",
    "        v='vfull',\n",
    "        KE='add(pow(ufull,2),pow(vfull,2))', # u^2 + v^2\n",
    "        Ens='pow(curl(ufull,vfull),2)', # (u_y - v_x)^2\n",
    "    )\n",
    "\n",
    "    spectral_quantities = [\n",
    "        'KEspec',\n",
    "        'Ensspec',\n",
    "        'KEflux',\n",
    "        'APEflux',\n",
    "        'APEgenspec',\n",
    "        'KEfrictionspec'\n",
    "    ]\n",
    "\n",
    "    differences = {}\n",
    "\n",
    "    for label, expr in distribution_quantities.items():\n",
    "        for z in [0,1]:\n",
    "            # Flatten over space and the last T timesteps\n",
    "            ts = slice(-T,None)\n",
    "            q1 = FeatureExtractor(ds1.isel(lev=z,time=ts))(expr).ravel()\n",
    "            q2 = FeatureExtractor(ds2.isel(lev=z,time=ts))(expr).ravel()\n",
    "            # Compute the empirical wasserstein distance\n",
    "            differences[f\"distrib_diff_{label}{z+1}\"] = WDL(q1, q2) #thisis wronglol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
