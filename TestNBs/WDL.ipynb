{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b1b1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "By Zhewen Hou\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.distributions.normal import Normal\n",
    "from scipy.stats import norm\n",
    "from sklearn import *\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "071818d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy implementation\n",
    "# def dgmm1d(x, mu, sigma, pi):\n",
    "#    pdf_gmm = np.sum([pi[k] * norm.pdf(x, loc=mu[k], scale=sigma[k]) for k in range(len(mu))], axis=0)\n",
    "#    return pdf_gmm\n",
    "\n",
    "# density of 1D Gaussian Mixture\n",
    "def dgmm1d(x: Tensor, mu: Tensor, sigma: Tensor, pi: Tensor) -> Tensor:\n",
    "    pdf_gmm = torch.sum(torch.stack([pi[k] * Normal(mu[k], sigma[k]).log_prob(x).exp() for k in range(len(mu))]), dim=0)\n",
    "    return pdf_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19cf6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy implementation\n",
    "# def pgmm1d(x, mu, sigma, pi):\n",
    "#    cdf_gmm = np.sum([pi[k] * norm.cdf(x, loc=mu[k], scale=sigma[k]) for k in range(len(mu))], axis=0)\n",
    "#    return cdf_gmm\n",
    "\n",
    "# cdf of 1D Gaussian Mixture\n",
    "def pgmm1d(x: Tensor, mu: Tensor, sigma: Tensor, pi: Tensor) -> Tensor:\n",
    "    cdf_gmm = torch.sum(torch.stack([pi[k] * Normal(mu[k], sigma[k]).cdf(x) for k in range(len(mu))]), dim=0)\n",
    "    return cdf_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be32138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy implementation: quantile of 1D Gaussian Mixture\n",
    "#def qgmm1d(q, mu, sigma, pi):\n",
    "#    ppf_full = np.array([norm.ppf(q, loc=mu[k], scale=sigma[k]) for k in range(len(mu))]).flatten()\n",
    "#    ppf_full.sort()\n",
    "#    cdf_gmm = np.sum([pi[k] * norm.cdf(ppf_full, loc=mu[k], scale=sigma[k]) for k in range(len(mu))], axis=0)\n",
    "#    ## 1D linear interpolation\n",
    "#    ppf_gmm = np.interp(q, cdf_gmm, ppf_full)\n",
    "#    return ppf_gmm\n",
    "\n",
    "# implementation of np.interp with pytorch\n",
    "def interp(x: Tensor, xp: Tensor, fp: Tensor) -> Tensor:\n",
    "    m = (fp[:, 1:] - fp[:, :-1]) / (xp[:, 1:] - xp[:, :-1])\n",
    "    b = fp[:, :-1] - (m * xp[:, :-1])\n",
    "\n",
    "    indicies = torch.sum(torch.ge(x[:, :, None], xp[:, None, :]), dim=2) - 1\n",
    "    indicies = torch.clamp(indicies, 0, len(m[0]) - 1)\n",
    "\n",
    "    return torch.gather(m, 1, indicies) * x + torch.gather(b, 1, indicies)\n",
    "\n",
    "\n",
    "# quantile of 1D Gaussian Mixture\n",
    "def qgmm1d(q: Tensor, mu: Tensor, sigma: Tensor, pi: Tensor) -> Tensor:\n",
    "    #print((Normal(mu, sigma).icdf(q.view(q.size(0), 1, 1).expand(q.size(0), mu.size(0), mu.size(1)))).shape)\n",
    "    ppf_full = torch.permute(Normal(mu, sigma).icdf(q.view(q.size(0), 1, 1).expand(q.size(0), mu.size(0), mu.size(1))),\n",
    "                             (1, 0, 2)).flatten(1)\n",
    "    # ppf_full = torch.permute(Normal(mu, sigma).icdf(q[:, None, None].expand(q.size(0), mu.size(0), mu.size(1))),\n",
    "    #                         (1, 0, 2)).flatten(1)\n",
    "    ppf_full= torch.sort(ppf_full, dim=1)[0]\n",
    "    cdf_gmm = torch.sum(pi[:, None] * Normal(mu[:, None], sigma[:, None]).cdf(ppf_full[:, :, None]), dim=2)\n",
    "    ppf_gmm = interp(q.expand(mu.size(0), -1), cdf_gmm, ppf_full)\n",
    "    return ppf_gmm.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed5f0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_dWasserstein(Y: Tensor, mu: Tensor, sigma: Tensor, pi: Tensor, q: Tensor, p: int = 2) -> Tensor:\n",
    "    ppf_gmm = qgmm1d(q, mu, sigma, pi)\n",
    "    #print(ppf_gmm.shape)\n",
    "    #print(Y.shape)\n",
    "    Wp = torch.mean((ppf_gmm - Y) ** p, dim=1) ** (1 / p)\n",
    "    return Wp\n",
    "\n",
    "\n",
    "# main functions for fitting Wasserstein mixture regression\n",
    "def WDL(Y, q_vec, mu, sd, pi):\n",
    "    \"\"\"\n",
    "    n: number of observations\n",
    "    m: number of percentiles \n",
    "    k: number of components in the GMM \n",
    "    :param Y: n x m\n",
    "    :param q_vec: m\n",
    "    :param mu: n x k, mean of the components in the GMM\n",
    "    :param sd: n x k, standard deviation of the components in the GMM\n",
    "    :param pi: n x k, mixing proportion of the components in the GMM\n",
    "    :return: mean distance between the empirical quantile function and the quantile function of the GMM\n",
    "    \"\"\"\n",
    "    # calculate the mean of the Wasserstein distance for each distribution of different X\n",
    "    w2 = torch.mean(batch_dWasserstein(Y, mu, sd, pi, q_vec) ** 2)\n",
    "    return w2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4d7da6",
   "metadata": {},
   "source": [
    "#### Testing Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f739f43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 300)\n",
      "[[-3.09883251 -2.86643922 -2.51388866 ...  4.31112254  4.3739572\n",
      "   5.20220006]\n",
      " [-2.91661178 -2.65928491 -2.44640414 ...  4.53591171  4.56868362\n",
      "   4.62578348]\n",
      " [-2.4340326  -2.40057418 -2.28007935 ...  5.02492275  5.16380261\n",
      "   5.78538448]\n",
      " ...\n",
      " [-2.46941656 -2.20831643 -2.10139391 ...  5.88877085  6.20330087\n",
      "   6.4078245 ]\n",
      " [-2.84557891 -2.6724476  -2.48777096 ...  4.07628841  4.22882558\n",
      "   4.26913273]\n",
      " [-3.17172267 -3.08769588 -3.08434324 ...  4.32627668  4.42752034\n",
      "   4.526383  ]]\n",
      "q_vec tensor([0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800, 0.0900,\n",
      "        0.1000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500, 0.1600, 0.1700, 0.1800,\n",
      "        0.1900, 0.2000, 0.2100, 0.2200, 0.2300, 0.2400, 0.2500, 0.2600, 0.2700,\n",
      "        0.2800, 0.2900, 0.3000, 0.3100, 0.3200, 0.3300, 0.3400, 0.3500, 0.3600,\n",
      "        0.3700, 0.3800, 0.3900, 0.4000, 0.4100, 0.4200, 0.4300, 0.4400, 0.4500,\n",
      "        0.4600, 0.4700, 0.4800, 0.4900, 0.5000, 0.5100, 0.5200, 0.5300, 0.5400,\n",
      "        0.5500, 0.5600, 0.5700, 0.5800, 0.5900, 0.6000, 0.6100, 0.6200, 0.6300,\n",
      "        0.6400, 0.6500, 0.6600, 0.6700, 0.6800, 0.6900, 0.7000, 0.7100, 0.7200,\n",
      "        0.7300, 0.7400, 0.7500, 0.7600, 0.7700, 0.7800, 0.7900, 0.8000, 0.8100,\n",
      "        0.8200, 0.8300, 0.8400, 0.8500, 0.8600, 0.8700, 0.8800, 0.8900, 0.9000,\n",
      "        0.9100, 0.9200, 0.9300, 0.9400, 0.9500, 0.9600, 0.9700, 0.9800, 0.9900],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# set parameters\n",
    "SEED = 234234\n",
    "K = 2 # number of components in the GMM\n",
    "n_dist = 300 ## number of distributions\n",
    "omega = 0.1 # default 0.1\n",
    "n_sample = 300\n",
    "\n",
    "# simulate the data\n",
    "np.random.seed(SEED)\n",
    "torch.random.manual_seed(SEED)\n",
    "X = np.random.uniform(size=(n_dist, 3)) * 2 - 1 # generate X\n",
    "Y = np.zeros((n_dist, n_sample)) # generate Y\n",
    "\n",
    "\n",
    "## simulate Y\n",
    "for i in range(n_dist):\n",
    "    mu_1 = X[i, 0]\n",
    "    mu_2 = 2 * X[i, 1]**2 + 2\n",
    "    mu_true = [mu_1, mu_2]\n",
    "    #print('mu:', mu_true)\n",
    "    sig_1 = np.abs(X[i, 1]) + 0.5\n",
    "    sig_2 = np.abs(X[i, 0]) + 0.5\n",
    "    sig_true = [sig_1, sig_2]\n",
    "    #print('sig:', sig_true)\n",
    "    pi_1 = 1 / (1 + np.exp(X[i, 2]))\n",
    "    pi_true = [pi_1, 1-pi_1]\n",
    "    #print('pi:', pi_true)\n",
    "    ## simulate noise\n",
    "    eps_noise = np.random.normal(loc=0, scale=omega, size=1)\n",
    "    ## simulate responses\n",
    "    var_gaussian = np.array([np.random.normal(loc=mu_true[k]+eps_noise,\n",
    "                                              scale=sig_true[k],\n",
    "                                              size=n_sample) for k in range(K)]).T\n",
    "    var_mult = np.random.choice(range(K), size=n_sample, replace=True, p=pi_true)\n",
    "    var_mult = np.eye(K)[var_mult]\n",
    "    var_GMM = np.sum(var_mult * var_gaussian, axis=1)\n",
    "    Y[i] = np.sort(var_GMM)\n",
    "    \n",
    "print(Y.shape)\n",
    "print(Y)\n",
    "\n",
    "# prepare for model fitting\n",
    "K_mix = 2\n",
    "n_iter = 1000\n",
    "lr = 1e-1\n",
    "v_lr = np.array([1] + [lr] * n_iter)\n",
    "n_dist = Y.shape[0]\n",
    "n_levs = 100\n",
    "q_vec = torch.arange(1, n_levs, dtype=torch.float64) / n_levs # quantile levels\n",
    "print('q_vec', q_vec)\n",
    "## transform Y\n",
    "Q_mat = np.array([np.quantile(Y[i], q_vec) for i in range(n_dist)]) # calculate the empirical quantile function\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1be7060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 2])\n",
      "tensor(3.3191, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.7576, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(10.8323, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.6517, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.2748, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(9.4206, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.4102, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(5.5286, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.3920, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.5275, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.7134, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.1449, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.6462, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(9.2059, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.0777, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.3325, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.4392, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.1750, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(9.7364, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.1114, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(1.8960, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(1.3682, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(7.1256, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.4552, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(9.9898, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.2970, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(7.3240, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(7.5528, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(5.5834, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.2871, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.9559, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(1.9131, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.1473, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.4339, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.0631, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.3605, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.5701, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(1.6211, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.3555, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.4561, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(9.7637, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(16.1550, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.1282, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.8693, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(5.8485, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.0552, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.4853, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(5.8448, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.3544, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(1.1943, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.9620, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(11.2251, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.1839, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.6112, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(12.6924, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.5020, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.7319, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(7.1041, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.0786, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(8.5303, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.3283, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.9600, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.6031, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.9778, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(8.4882, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(13.2996, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.2756, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.6197, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.2224, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.3937, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.9111, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.8435, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(1.6509, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.2654, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(1.3037, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.8720, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(5.5922, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.3670, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.5407, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(1.9394, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.8822, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.6176, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.7847, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(7.1018, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.0455, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.0082, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(5.0317, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.3229, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(8.9892, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.5363, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.2305, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.2745, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(3.9015, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(7.4726, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.4527, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.9019, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.2876, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(6.0923, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(4.8266, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "torch.Size([240, 2])\n",
      "tensor(2.1086, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
      "4.790149927139282\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# step 1. train-val split\n",
    "n_train = int(0.8 * n_dist)\n",
    "loc_train = np.random.choice(n_dist, n_train, replace=False)\n",
    "loc_val = np.setdiff1d(np.arange(n_dist), loc_train)\n",
    "\n",
    "\n",
    "X_train = torch.tensor(X[loc_train])\n",
    "# generate true parameters\n",
    "mu_true = torch.cat((X_train[:, 0].unsqueeze(dim=1), (2 * X_train[:, 1] ** 2 + 2).unsqueeze(dim=1)), dim=1)\n",
    "sd_true = torch.cat(\n",
    "    (torch.abs(X_train[:, 1]).unsqueeze(dim=1) + 0.5, torch.abs(X_train[:, 0]).unsqueeze(dim=1) + 0.5), dim=1)\n",
    "alpha_true = torch.cat((torch.zeros_like(X_train[:, 2].unsqueeze(dim=1)), X_train[:, 2].unsqueeze(dim=1)), dim=1)\n",
    "pi_true = torch.softmax(alpha_true, dim=1)\n",
    "\n",
    "# generate features\n",
    "X_train = torch.cat((X_train, torch.abs(X_train), X_train ** 2), 1)\n",
    "y_train = torch.tensor(Q_mat[loc_train])\n",
    "X_val = torch.tensor(X[loc_val])\n",
    "X_val = torch.cat((X_val, torch.abs(X_val), X_val ** 2), 1)\n",
    "y_val = torch.tensor(Q_mat[loc_val])\n",
    "\n",
    "\n",
    "# test the speed of the loss function\n",
    "start = time.time()\n",
    "\n",
    "for i in range(100):\n",
    "    alpha_matrix = torch.tensor(np.random.randn(9, 2), requires_grad=True)\n",
    "    mu_matrix = torch.tensor(np.random.randn(9, 2), requires_grad=True)\n",
    "    sd_matrix = torch.tensor(np.random.randn(9, 2), requires_grad=True)\n",
    "\n",
    "    alpha = torch.matmul(X_train, alpha_matrix)\n",
    "    pi = torch.softmax(alpha, dim=1)\n",
    "\n",
    "    mu = torch.matmul(X_train, mu_matrix)\n",
    "    \n",
    "    sd = torch.abs(torch.matmul(X_train, sd_matrix))\n",
    "\n",
    "    loss = WDL(y_train, q_vec, mu, sd, pi)\n",
    "\n",
    "    print(loss)\n",
    "print(time.time() - start)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c8383b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.8953202843639845\n",
      "1 1.3534818272009868\n",
      "2 1.1289146756614765\n",
      "3 0.9695439868641276\n",
      "4 0.8410743849086068\n",
      "5 0.7460565953840385\n",
      "6 0.6636767057837374\n",
      "7 0.5848967261742131\n",
      "8 0.5266667713177535\n",
      "9 0.4884040086465751\n",
      "10 0.4627104085141768\n",
      "11 0.4445376934490593\n",
      "12 0.4312602267888029\n",
      "13 0.42104361181653877\n",
      "14 0.4129402232543243\n",
      "15 0.4062451190122733\n",
      "16 0.4004599705522235\n",
      "17 0.39538086100784203\n",
      "18 0.3908074570266714\n",
      "19 0.3866144693195827\n",
      "20 0.38270288903928823\n",
      "21 0.379027041679309\n",
      "22 0.3755465731476292\n",
      "23 0.3722398365090432\n",
      "24 0.3690815793859981\n",
      "25 0.36605019903641384\n",
      "26 0.3631314508306239\n",
      "27 0.360317832741287\n",
      "28 0.3576081756014649\n",
      "29 0.35498246209752826\n",
      "30 0.3524420986209344\n",
      "31 0.3499822246531771\n",
      "32 0.34761627252171307\n",
      "33 0.34533445048140243\n",
      "34 0.34314551886775635\n",
      "35 0.34104293787801937\n",
      "36 0.3390550776236632\n",
      "37 0.33718703170860564\n",
      "38 0.33544796533789367\n",
      "39 0.3338419256028747\n",
      "40 0.3324518168267894\n",
      "41 0.3312934539459188\n",
      "42 0.33045108734716455\n",
      "43 0.329935288878456\n",
      "44 0.32999522922057495\n",
      "45 0.33071378442414506\n",
      "46 0.3323803067388282\n",
      "47 0.33533719811649354\n",
      "48 0.34006035130405216\n",
      "49 0.3467083122028573\n",
      "50 0.3569573511703948\n",
      "51 0.3708016261509755\n",
      "52 0.3912432955087108\n",
      "53 0.4185125448961473\n",
      "54 0.45890190586436586\n",
      "55 0.5114247207223532\n",
      "56 0.589605039167174\n",
      "57 0.6901370234669731\n",
      "58 0.8426615503568449\n",
      "59 1.0329297560912996\n",
      "60 1.3350092501725257\n",
      "61 1.6204772708302395\n",
      "62 0.7281202535854452\n",
      "63 0.8353551070961639\n",
      "64 0.850116001815361\n",
      "65 0.9958535446932112\n",
      "66 1.0019186228553802\n",
      "67 1.1698596508557582\n",
      "68 1.0259213137745853\n",
      "69 1.1744898587259052\n",
      "70 0.9202079280538172\n",
      "71 1.03543978516339\n",
      "72 0.8911526678523034\n",
      "73 0.99857446002752\n",
      "74 0.8685278550208874\n",
      "75 0.970622214192291\n",
      "76 0.851809084720123\n",
      "77 0.9495233721380173\n",
      "78 0.8419070994929974\n",
      "79 0.9362333858837627\n",
      "80 0.861328617770162\n",
      "81 0.9565711693876757\n",
      "82 0.8761732519640221\n",
      "83 0.969021072731697\n",
      "84 0.8863109866627225\n",
      "85 0.9730622471932769\n",
      "86 0.8848856420848925\n",
      "87 0.964328914755203\n",
      "88 0.8654315337342823\n",
      "89 0.9350988375435283\n",
      "90 0.8508167370008425\n",
      "91 0.9133195786856463\n",
      "92 0.8343599139606821\n",
      "93 0.8899455632639854\n",
      "94 0.8480767471536351\n",
      "95 0.8998254873553768\n",
      "96 0.8485405225012469\n",
      "97 0.8933105282440271\n",
      "98 0.8952137676753743\n",
      "99 0.9356724295409601\n",
      "100 0.8281313931738289\n",
      "101 0.8528665057810657\n",
      "102 0.8315750353676798\n",
      "103 0.8504907849383049\n",
      "104 0.8513482818293807\n",
      "105 0.8643090548115786\n",
      "106 0.8590619349376928\n",
      "107 0.8625054377662994\n",
      "108 0.8482790509284414\n",
      "109 0.8418202911138077\n",
      "110 0.8155227622826777\n",
      "111 0.7994593518414208\n",
      "112 0.8105217959309502\n",
      "113 0.7870263916253578\n",
      "114 0.7930487770040635\n",
      "115 0.7622525011390034\n",
      "116 0.7578521323348084\n",
      "117 0.7226036380088611\n",
      "118 0.7116738071447887\n",
      "119 0.675082250377239\n",
      "120 0.6622378201760288\n",
      "121 0.6264330397386608\n",
      "122 0.6110257752458507\n",
      "123 0.5797954594842916\n",
      "124 0.5644243415802908\n",
      "125 0.5377455066280425\n",
      "126 0.5259468934811327\n",
      "127 0.5042144588112158\n",
      "128 0.4946364713088686\n",
      "129 0.47758193217868533\n",
      "130 0.4709357010468603\n",
      "131 0.4584165714815774\n",
      "132 0.4534276792374963\n",
      "133 0.44376612969921825\n",
      "134 0.4408814032730943\n",
      "135 0.43357794605247996\n",
      "136 0.43247097115586425\n",
      "137 0.42757874421003755\n",
      "138 0.4280872719556596\n",
      "139 0.42427906974940865\n",
      "140 0.42686731248202\n",
      "141 0.42456655484636313\n",
      "142 0.4284811735603566\n",
      "143 0.4276284433226408\n",
      "144 0.4328155932012837\n",
      "145 0.4328903579345917\n",
      "146 0.439840437825991\n",
      "147 0.4408423148940575\n",
      "148 0.44850461622121757\n",
      "149 0.4496850250090128\n",
      "150 0.4590423308919471\n",
      "151 0.46074796168010834\n",
      "152 0.471040353864468\n",
      "153 0.4734399923630158\n",
      "154 0.4842839203591615\n",
      "155 0.48597729759727903\n",
      "156 0.4971285825892625\n",
      "157 0.4976014601658786\n",
      "158 0.5085574567183804\n",
      "159 0.5078960538676384\n",
      "160 0.5181335095704362\n",
      "161 0.5151992559938187\n",
      "162 0.5245150215710827\n",
      "163 0.5201686853561149\n",
      "164 0.527895366512534\n",
      "165 0.5212616839971066\n",
      "166 0.5267376438445759\n",
      "167 0.5175769657067485\n",
      "168 0.5197426896083763\n",
      "169 0.5078228326558832\n",
      "170 0.5078413060911521\n",
      "171 0.3640881435887368\n",
      "172 0.30421403553581067\n",
      "173 0.27604802607411577\n",
      "174 0.2636979531719385\n",
      "175 0.2577996722251007\n",
      "176 0.2548837893144916\n",
      "177 0.25327371998947296\n",
      "178 0.2522766772528721\n",
      "179 0.25157050192401087\n",
      "180 0.2509852424150446\n",
      "181 0.2504915772915893\n",
      "182 0.25004183353220694\n",
      "183 0.24961845697870652\n",
      "184 0.24921919132059023\n",
      "185 0.24883819967825926\n",
      "186 0.24847381091530274\n",
      "187 0.2481223582058719\n",
      "188 0.24778462899471027\n",
      "189 0.2474574298350933\n",
      "190 0.247145244465247\n",
      "191 0.2468425160680477\n",
      "192 0.24654913789441282\n",
      "193 0.24626477810059247\n",
      "194 0.24598851087250317\n",
      "195 0.24572083965608033\n",
      "196 0.24545749431389846\n",
      "197 0.24519931498113268\n",
      "198 0.2449479650310643\n",
      "199 0.24470361040846936\n",
      "200 0.24446703120079097\n",
      "201 0.2442376899475967\n",
      "202 0.2440139774404511\n",
      "203 0.24379596988549687\n",
      "204 0.2435835235286739\n",
      "205 0.24337659107178272\n",
      "206 0.2431724002074261\n",
      "207 0.24297276144877528\n",
      "208 0.2427778845948915\n",
      "209 0.24258759738678487\n",
      "210 0.24240040589378511\n",
      "211 0.24221416776952112\n",
      "212 0.24203209425729574\n",
      "213 0.24185302396321953\n",
      "214 0.24167794752569063\n",
      "215 0.24150663819147428\n",
      "216 0.24133975628097454\n",
      "217 0.24117620010897783\n",
      "218 0.24101462705618962\n",
      "219 0.24085608972859535\n",
      "220 0.240700700882917\n",
      "221 0.240547483006839\n",
      "222 0.24039886913802325\n",
      "223 0.24025216181774425\n",
      "224 0.24010658072864247\n",
      "225 0.23996388445743794\n",
      "226 0.2398232186706175\n",
      "227 0.23968544840179468\n",
      "228 0.23955039752572047\n",
      "229 0.23941767411435974\n",
      "230 0.2392868298823851\n",
      "231 0.2391556770883082\n",
      "232 0.2390268562177897\n",
      "233 0.2389012043029684\n",
      "234 0.23877801390705436\n",
      "235 0.2386567024308671\n",
      "236 0.23853716376130774\n",
      "237 0.23841840670508868\n",
      "238 0.23830007633899228\n",
      "239 0.2381822258942143\n",
      "240 0.2380646108741139\n",
      "241 0.23795043846039904\n",
      "242 0.23783784431293267\n",
      "243 0.23772723425557396\n",
      "244 0.23761876638172064\n",
      "245 0.2375111917545389\n",
      "246 0.2374052771766778\n",
      "247 0.23730031681172736\n",
      "248 0.23719635792636595\n",
      "249 0.23709455709299784\n",
      "250 0.23699342011759436\n",
      "251 0.2368920961667282\n",
      "252 0.23679139866028187\n",
      "253 0.2366910843546133\n",
      "254 0.23659091635171972\n",
      "255 0.23649142725946062\n",
      "256 0.23639383047401996\n",
      "257 0.23629680299985084\n",
      "258 0.23620032281316408\n",
      "259 0.23610585439391726\n",
      "260 0.2360133068147265\n",
      "261 0.2359212133584682\n",
      "262 0.23583234398576117\n",
      "263 0.23574352402055154\n",
      "264 0.23565459096890637\n",
      "265 0.23556613516819472\n",
      "266 0.23547825198414044\n",
      "267 0.23539111415229647\n",
      "268 0.23530365214940757\n",
      "269 0.23521654842794282\n",
      "270 0.23513132657714034\n",
      "271 0.2350485477115099\n",
      "272 0.23496618468131633\n",
      "273 0.2348851877866651\n",
      "274 0.23480510431310808\n",
      "275 0.23472509466476435\n",
      "276 0.2346457641636455\n",
      "277 0.2345671369538679\n",
      "278 0.23448901095235125\n",
      "279 0.2344110938192013\n",
      "280 0.23433414589905688\n",
      "281 0.23425773452917634\n",
      "282 0.23418225605595577\n",
      "283 0.2341075585583775\n",
      "284 0.23403394082031367\n",
      "285 0.2339601581914424\n",
      "286 0.23388673408135965\n",
      "287 0.23381472910583956\n",
      "288 0.23374335716847205\n",
      "289 0.2336722416076503\n",
      "290 0.23360222933565097\n",
      "291 0.23353232030589682\n",
      "292 0.23346250639757501\n",
      "293 0.23339265074934926\n",
      "294 0.23332363576791382\n",
      "295 0.23325544955692046\n",
      "296 0.23318754036265824\n",
      "297 0.2331196955697226\n",
      "298 0.23305214428997098\n",
      "299 0.23298495125868876\n",
      "300 0.23291909946910708\n",
      "301 0.2328529699703435\n",
      "302 0.23278740717404658\n",
      "303 0.23272242481236258\n",
      "304 0.23265826145593285\n",
      "305 0.23259448535836466\n",
      "306 0.23253120655317538\n",
      "307 0.23246832791820377\n",
      "308 0.2324050001988418\n",
      "309 0.23234199416532783\n",
      "310 0.2322792929662155\n",
      "311 0.23221724174935726\n",
      "312 0.2321551821564869\n",
      "313 0.23209355840653156\n",
      "314 0.23203255935936765\n",
      "315 0.23197184026401937\n",
      "316 0.23191179228206382\n",
      "317 0.23185186777218844\n",
      "318 0.2317924135112804\n",
      "319 0.23173345306927728\n",
      "320 0.23167502320153696\n",
      "321 0.23161702382220772\n",
      "322 0.2315594054058387\n",
      "323 0.23150229430670463\n",
      "324 0.23144514761621116\n",
      "325 0.23138753585885385\n",
      "326 0.23133022326149588\n",
      "327 0.23127306153315802\n",
      "328 0.23121630437076265\n",
      "329 0.2311599986846708\n",
      "330 0.2311030095526016\n",
      "331 0.23104640118713024\n",
      "332 0.23099056750990793\n",
      "333 0.23093494734285736\n",
      "334 0.23087959412091544\n",
      "335 0.23082405701465517\n",
      "336 0.23076846952347066\n",
      "337 0.2307137049759201\n",
      "338 0.23065806671986963\n",
      "339 0.23060293538933946\n",
      "340 0.23054805415122248\n",
      "341 0.23050183245891573\n",
      "342 0.2304559044524082\n",
      "343 0.2304097432499415\n",
      "344 0.23036311799857823\n",
      "345 0.23031664144126035\n",
      "346 0.23027074326982916\n",
      "347 0.2302258923651939\n",
      "348 0.23018135080318933\n",
      "349 0.23013685918678128\n",
      "350 0.23009231149009696\n",
      "351 0.2300477834134759\n",
      "352 0.23000355336469178\n",
      "353 0.22995937916982084\n",
      "354 0.22991532326548836\n",
      "355 0.2298711890832533\n",
      "356 0.22982684779226686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357 0.229782807696876\n",
      "358 0.22973927574679262\n",
      "359 0.22969532287394812\n",
      "360 0.22965191514094574\n",
      "361 0.22960868005414736\n",
      "362 0.22956475494083023\n",
      "363 0.2295210815989688\n",
      "364 0.22947797990538116\n",
      "365 0.22943574721111146\n",
      "366 0.22939352814827402\n",
      "367 0.2293515024914417\n",
      "368 0.22930978099982874\n",
      "369 0.22926818707888863\n",
      "370 0.22922623295609354\n",
      "371 0.2291843900285459\n",
      "372 0.2291427756019279\n",
      "373 0.22910128174218394\n",
      "374 0.22906004098120042\n",
      "375 0.2290192402148177\n",
      "376 0.22897839624326904\n",
      "377 0.22893743902574137\n",
      "378 0.22889648481200867\n",
      "379 0.22885560519539255\n",
      "380 0.22881504708271502\n",
      "381 0.22877472960735712\n",
      "382 0.22873457876907985\n",
      "383 0.22869445473911915\n",
      "384 0.2286544491594006\n",
      "385 0.22861426596520606\n",
      "386 0.22857374882523296\n",
      "387 0.2285334578519921\n",
      "388 0.22849328004210206\n",
      "389 0.2284536787905523\n",
      "390 0.22841372905912394\n",
      "391 0.22837366785901717\n",
      "392 0.22833344268351657\n",
      "393 0.2282935780287301\n",
      "394 0.22825399282671052\n",
      "395 0.2282144914917676\n",
      "396 0.22817536085882806\n",
      "397 0.22813652017116812\n",
      "398 0.22809742568554786\n",
      "399 0.2280584239033732\n",
      "400 0.22801951171098978\n",
      "401 0.2279802843297443\n",
      "402 0.22794088025833817\n",
      "403 0.22790166478640134\n",
      "404 0.22786242151505195\n",
      "405 0.227823152947911\n",
      "406 0.2277838266913947\n",
      "407 0.2277443001001331\n",
      "408 0.2277044403604059\n",
      "409 0.22766472792925174\n",
      "410 0.22762558258555063\n",
      "411 0.22758640681763437\n",
      "412 0.22754729582529\n",
      "413 0.22750845717416998\n",
      "414 0.22746968837184783\n",
      "415 0.22743092504877835\n",
      "416 0.22739220983894898\n",
      "417 0.22735366654490494\n",
      "418 0.2273150340266108\n",
      "419 0.2272762219417635\n",
      "420 0.2272376027648183\n",
      "421 0.22719936257318996\n",
      "422 0.22716173329055114\n",
      "423 0.2271242434093118\n",
      "424 0.22708615954032801\n",
      "425 0.22704817043471603\n",
      "426 0.22701015336018385\n",
      "427 0.2269724296972378\n",
      "428 0.22693502256979578\n",
      "429 0.22689783135307057\n",
      "430 0.22686034785574172\n",
      "431 0.2268227125174716\n",
      "432 0.22678535458319413\n",
      "433 0.22674773320781108\n",
      "434 0.2267101042130638\n",
      "435 0.22667218198275532\n",
      "436 0.2266351208222672\n",
      "437 0.2265979856761363\n",
      "438 0.22656090865526993\n",
      "439 0.22652375340165995\n",
      "440 0.22648659388427575\n",
      "441 0.2264493740213171\n",
      "442 0.226412052659079\n",
      "443 0.2263745080574002\n",
      "444 0.22633694808292384\n",
      "445 0.22629927752043083\n",
      "446 0.22626175592876605\n",
      "447 0.22622418369373729\n",
      "448 0.22618654383137968\n",
      "449 0.2261489489030298\n",
      "450 0.22611159306051534\n",
      "451 0.22607431920909252\n",
      "452 0.22603710590039808\n",
      "453 0.22599933819193377\n",
      "454 0.22596107061667584\n",
      "455 0.22592278893547668\n",
      "456 0.22588459074004655\n",
      "457 0.22584626429821567\n",
      "458 0.2258078122145467\n",
      "459 0.22576958828358945\n",
      "460 0.2257316395612549\n",
      "461 0.22569371144380862\n",
      "462 0.2256562101819562\n",
      "463 0.22561880042201332\n",
      "464 0.225581063473309\n",
      "465 0.22554258396824303\n",
      "466 0.22550353082789368\n",
      "467 0.22546386118026696\n",
      "468 0.22542437911933133\n",
      "469 0.22538575786280254\n",
      "470 0.22534716780306835\n",
      "471 0.2253083620120316\n",
      "472 0.22527006363644242\n",
      "473 0.2252316943667503\n",
      "474 0.22519318015966436\n",
      "475 0.22515506457005255\n",
      "476 0.22511676067414627\n",
      "477 0.2250780160437369\n",
      "478 0.22503945810909948\n",
      "479 0.22500114161945242\n",
      "480 0.22496264816681827\n",
      "481 0.2249242938900166\n",
      "482 0.22488641443791468\n",
      "483 0.2248492651264288\n",
      "484 0.2248120224122358\n",
      "485 0.2247744842267451\n",
      "486 0.22473680473955823\n",
      "487 0.22469954960729552\n",
      "488 0.22466243093492808\n",
      "489 0.2246250628336576\n",
      "490 0.22458751068783045\n",
      "491 0.2245499550554356\n",
      "492 0.2245122612068044\n",
      "493 0.22447391867377395\n",
      "494 0.2244355971318383\n",
      "495 0.22439699916942954\n",
      "496 0.22435834857607903\n",
      "497 0.22431971945111667\n",
      "498 0.22428090455076388\n",
      "499 0.22424222337927055\n",
      "500 0.22420356320605148\n",
      "501 0.22416482104232452\n",
      "502 0.22412631846242254\n",
      "503 0.22408806353420188\n",
      "504 0.22405002496058765\n",
      "505 0.22401190561606077\n",
      "506 0.22397381848004033\n",
      "507 0.22393568274841638\n",
      "508 0.2238974414055372\n",
      "509 0.22385939997671145\n",
      "510 0.223821378137333\n",
      "511 0.22378943894194978\n",
      "512 0.2237571740032385\n",
      "513 0.2237247143601475\n",
      "514 0.22369233490993562\n",
      "515 0.2236601214346128\n",
      "516 0.22362798833700767\n",
      "517 0.22359601483895222\n",
      "518 0.22356432642262572\n",
      "519 0.22353285401294645\n",
      "520 0.22350137508733064\n",
      "521 0.22346964834401917\n",
      "522 0.22343773247473478\n",
      "523 0.22340520715942203\n",
      "524 0.22337206015097527\n",
      "525 0.22333909223816578\n",
      "526 0.22330712531418612\n",
      "527 0.22327496700260066\n",
      "528 0.22324265411276567\n",
      "529 0.223210197853671\n",
      "530 0.22317783699260657\n",
      "531 0.2231455800574095\n",
      "532 0.2231132561433729\n",
      "533 0.22308082179250385\n",
      "534 0.22304834859818362\n",
      "535 0.22301601894739906\n",
      "536 0.2229838013021404\n",
      "537 0.22295086492885166\n",
      "538 0.2229180712116271\n",
      "539 0.22288619567974627\n",
      "540 0.2228543148924759\n",
      "541 0.22282198569197018\n",
      "542 0.22278943168126855\n",
      "543 0.22275691598032052\n",
      "544 0.22272442363399064\n",
      "545 0.22269218272422467\n",
      "546 0.22266015255339403\n",
      "547 0.22262800694921267\n",
      "548 0.2225959705500723\n",
      "549 0.22256403663363838\n",
      "550 0.22253218383256967\n",
      "551 0.22249980083812584\n",
      "552 0.2224674771958389\n",
      "553 0.22243487155839434\n",
      "554 0.22240200207848054\n",
      "555 0.22236895586540642\n",
      "556 0.22233570797860555\n",
      "557 0.2223017848925096\n",
      "558 0.2222679690909572\n",
      "559 0.22223443780390148\n",
      "560 0.2222013393839538\n",
      "561 0.22216828265313585\n",
      "562 0.222135353173476\n",
      "563 0.22210249027630666\n",
      "564 0.2220696468864984\n",
      "565 0.22203682672053338\n",
      "566 0.22200397532222318\n",
      "567 0.22197101013419515\n",
      "568 0.22193766169186357\n",
      "569 0.22190323196264156\n",
      "570 0.2218692923759164\n",
      "571 0.22183556531405813\n",
      "572 0.22180177022187048\n",
      "573 0.22176796442809638\n",
      "574 0.22173403122720134\n",
      "575 0.2217001955691829\n",
      "576 0.22166619644595648\n",
      "577 0.22163173172019293\n",
      "578 0.2215974377237145\n",
      "579 0.22156322086537583\n",
      "580 0.22152888850949956\n",
      "581 0.22149426450444504\n",
      "582 0.22145969495150186\n",
      "583 0.2214251782520725\n",
      "584 0.22139024065055016\n",
      "585 0.22135517043085615\n",
      "586 0.22131996133568552\n",
      "587 0.22128515988456648\n",
      "588 0.22125029754450454\n",
      "589 0.22121525622958432\n",
      "590 0.22117987454634672\n",
      "591 0.22114400681893245\n",
      "592 0.22110831220692984\n",
      "593 0.22107350494942\n",
      "594 0.22103839935438158\n",
      "595 0.22100378594259845\n",
      "596 0.22096932914076853\n",
      "597 0.22093496120361855\n",
      "598 0.22090081953196478\n",
      "599 0.22086630015165137\n",
      "600 0.2208315844393394\n",
      "601 0.2207963012768995\n",
      "602 0.220761175265577\n",
      "603 0.22072687753332698\n",
      "604 0.220692651920747\n",
      "605 0.2206588217811056\n",
      "606 0.22062522457016204\n",
      "607 0.2205912644826877\n",
      "608 0.22055672140595367\n",
      "609 0.22052260096783302\n",
      "610 0.2204886254967197\n",
      "611 0.22045443083508684\n",
      "612 0.22042005434170245\n",
      "613 0.22038534914476013\n",
      "614 0.22035069994805703\n",
      "615 0.22031589625029097\n",
      "616 0.22028105617931948\n",
      "617 0.2202460315531883\n",
      "618 0.22021062540909764\n",
      "619 0.22017530265167048\n",
      "620 0.22014029529857268\n",
      "621 0.22010498435353346\n",
      "622 0.22006980368080026\n",
      "623 0.22003474813512885\n",
      "624 0.2199996991395403\n",
      "625 0.21996463250213472\n",
      "626 0.21992968957343279\n",
      "627 0.21989471786126114\n",
      "628 0.21985952957658347\n",
      "629 0.21982449121035005\n",
      "630 0.21978945173972164\n",
      "631 0.21975439261262858\n",
      "632 0.21971940718736477\n",
      "633 0.21968472994178637\n",
      "634 0.21964998112214099\n",
      "635 0.21961510518880062\n",
      "636 0.21957996126784074\n",
      "637 0.21954485744410893\n",
      "638 0.2195095192009306\n",
      "639 0.2194739335496676\n",
      "640 0.21943799510189846\n",
      "641 0.21940200783749508\n",
      "642 0.2193664004658989\n",
      "643 0.2193301124346724\n",
      "644 0.21929326122927703\n",
      "645 0.21925602375832237\n",
      "646 0.21921877636509637\n",
      "647 0.2191820537445315\n",
      "648 0.21914523498563973\n",
      "649 0.21910878626307173\n",
      "650 0.2190726897823298\n",
      "651 0.21903681188524265\n",
      "652 0.21900045230744458\n",
      "653 0.21896410673964822\n",
      "654 0.21892808487405588\n",
      "655 0.2188918816890922\n",
      "656 0.21885560239467688\n",
      "657 0.21881878499893084\n",
      "658 0.2187823586134863\n",
      "659 0.21874611004589126\n",
      "660 0.21871038396726245\n",
      "661 0.2186747858177422\n",
      "662 0.21863948579167836\n",
      "663 0.21860399361657332\n",
      "664 0.2185681703699928\n",
      "665 0.2185321284061489\n",
      "666 0.2184958856738722\n",
      "667 0.2184593442168952\n",
      "668 0.2184227694343365\n",
      "669 0.21838628400427632\n",
      "670 0.21835040705846342\n",
      "671 0.2183143670040036\n",
      "672 0.21827805637652492\n",
      "673 0.21824186946130444\n",
      "674 0.2182061328515151\n",
      "675 0.21817054690591872\n",
      "676 0.21813507730818354\n",
      "677 0.21809951653523463\n",
      "678 0.21806393820791922\n",
      "679 0.21802872584981542\n",
      "680 0.21799361458743774\n",
      "681 0.21796404570613367\n",
      "682 0.21793447550822387\n",
      "683 0.2179048505813996\n",
      "684 0.2178749513002258\n",
      "685 0.2178450636759361\n",
      "686 0.21781517981084153\n",
      "687 0.21778520904364065\n",
      "688 0.21775518875553954\n",
      "689 0.2177251964921269\n",
      "690 0.21769538030216853\n",
      "691 0.21766549434539945\n",
      "692 0.21763565935666046\n",
      "693 0.21760596858294934\n",
      "694 0.21757648144973477\n",
      "695 0.21754667981274156\n",
      "696 0.21751663011834577\n",
      "697 0.2174862398688096\n",
      "698 0.2174555978216291\n",
      "699 0.21742533374715642\n",
      "700 0.21739524447922717\n",
      "701 0.2173652528907689\n",
      "702 0.21733495982099485\n",
      "703 0.21730463241558465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704 0.21727433258976012\n",
      "705 0.217243830528807\n",
      "706 0.21721328847861296\n",
      "707 0.217182694039943\n",
      "708 0.217152193898954\n",
      "709 0.21712178421433764\n",
      "710 0.21709130430211407\n",
      "711 0.21706083972909576\n",
      "712 0.21703028522505444\n",
      "713 0.21699983631903605\n",
      "714 0.2169691645948607\n",
      "715 0.21693844457732112\n",
      "716 0.21690760832696887\n",
      "717 0.21687669246277633\n",
      "718 0.21684574423048394\n",
      "719 0.21681483269126864\n",
      "720 0.21678392413437755\n",
      "721 0.21675310532729608\n",
      "722 0.21672232702925734\n",
      "723 0.21669131159030464\n",
      "724 0.21666057232522012\n",
      "725 0.21662957638775163\n",
      "726 0.2165986180098112\n",
      "727 0.21656802905653125\n",
      "728 0.21653730720190842\n",
      "729 0.21650644488418452\n",
      "730 0.2164752089620812\n",
      "731 0.2164438389158318\n",
      "732 0.21641251897786293\n",
      "733 0.2163814576374238\n",
      "734 0.2163503619391959\n",
      "735 0.21631913117259532\n",
      "736 0.21628793248769487\n",
      "737 0.21625669535489375\n",
      "738 0.21622538363958915\n",
      "739 0.21619384026412206\n",
      "740 0.21616083557601007\n",
      "741 0.2161272286383427\n",
      "742 0.21609435347357778\n",
      "743 0.21606118953875514\n",
      "744 0.21602802774804297\n",
      "745 0.21599539361971978\n",
      "746 0.2159626806464429\n",
      "747 0.2159295146666605\n",
      "748 0.21589678407949683\n",
      "749 0.21586426086441463\n",
      "750 0.21583151876806733\n",
      "751 0.21579864159016754\n",
      "752 0.21576596992816982\n",
      "753 0.21573366246864326\n",
      "754 0.2157013338043126\n",
      "755 0.21566913570718677\n",
      "756 0.21563730643035417\n",
      "757 0.21560569062349183\n",
      "758 0.21557417033222961\n",
      "759 0.21554239756044385\n",
      "760 0.2155108349886289\n",
      "761 0.21547934795733678\n",
      "762 0.21544786409742625\n",
      "763 0.21541618896064305\n",
      "764 0.21538451437296433\n",
      "765 0.21535318079899077\n",
      "766 0.21532198980667233\n",
      "767 0.21529083894054252\n",
      "768 0.21525896404066022\n",
      "769 0.21522729926773235\n",
      "770 0.21519566600773316\n",
      "771 0.21516366967843373\n",
      "772 0.21513182288455468\n",
      "773 0.21509967433418906\n",
      "774 0.21506718624766336\n",
      "775 0.21503427751157717\n",
      "776 0.21500209807956316\n",
      "777 0.21497032424815982\n",
      "778 0.21493876009509424\n",
      "779 0.21490729612769874\n",
      "780 0.21487593057824136\n",
      "781 0.21484442703075515\n",
      "782 0.2148123448140834\n",
      "783 0.2147798109132589\n",
      "784 0.2147472863566225\n",
      "785 0.21471497902416364\n",
      "786 0.21468236752771624\n",
      "787 0.2146495425350659\n",
      "788 0.21461658028822628\n",
      "789 0.21458368626162241\n",
      "790 0.2145507396970956\n",
      "791 0.2145178221257609\n",
      "792 0.21448510696888157\n",
      "793 0.21445273518949443\n",
      "794 0.21442053924616217\n",
      "795 0.2143882854114247\n",
      "796 0.21435609227819327\n",
      "797 0.2143242324784266\n",
      "798 0.21429262191310539\n",
      "799 0.2142616745099217\n",
      "800 0.21423082045838418\n",
      "801 0.21419983500066087\n",
      "802 0.21416864013473388\n",
      "803 0.21413723691349523\n",
      "804 0.21410591469865922\n",
      "805 0.21407478424052692\n",
      "806 0.21404379940898716\n",
      "807 0.21401281375155953\n",
      "808 0.21398179613333937\n",
      "809 0.2139508527557494\n",
      "810 0.2139200874861711\n",
      "811 0.21388912367203056\n",
      "812 0.2138582874332689\n",
      "813 0.2138270431536645\n",
      "814 0.21379590710941276\n",
      "815 0.2137646034278851\n",
      "816 0.21373318654378454\n",
      "817 0.21370107743047187\n",
      "818 0.21366916113956233\n",
      "819 0.21363735350705515\n",
      "820 0.2136048289080441\n",
      "821 0.213572344150487\n",
      "822 0.2135400196107982\n",
      "823 0.21350822891240404\n",
      "824 0.21347648594342278\n",
      "825 0.21344469757528256\n",
      "826 0.2134124621986369\n",
      "827 0.21337996931332334\n",
      "828 0.2133476147802867\n",
      "829 0.2133155839152068\n",
      "830 0.21328361194085488\n",
      "831 0.21325185044750497\n",
      "832 0.21322017124085105\n",
      "833 0.21318837163086535\n",
      "834 0.21315673858482415\n",
      "835 0.2131253764910897\n",
      "836 0.21309383536978163\n",
      "837 0.21306214914416272\n",
      "838 0.21303066726056566\n",
      "839 0.2129990908507424\n",
      "840 0.21296750968274208\n",
      "841 0.21293557515356415\n",
      "842 0.2129037386504435\n",
      "843 0.2128718742769978\n",
      "844 0.21283997085836506\n",
      "845 0.2128082780757508\n",
      "846 0.21277660751088026\n",
      "847 0.21274469468425397\n",
      "848 0.2127129119359101\n",
      "849 0.21268089553203737\n",
      "850 0.21264884954037447\n",
      "851 0.212622169848483\n",
      "852 0.212595304704247\n",
      "853 0.2125683324637625\n",
      "854 0.21254142473878573\n",
      "855 0.2125145892815049\n",
      "856 0.2124879831021109\n",
      "857 0.21246147049170036\n",
      "858 0.212434786901211\n",
      "859 0.21240829070812198\n",
      "860 0.21238170069554915\n",
      "861 0.21235497923381413\n",
      "862 0.21232849272354073\n",
      "863 0.21230222703666612\n",
      "864 0.2122760436201653\n",
      "865 0.21224960511314037\n",
      "866 0.21222309911228757\n",
      "867 0.21219657191100566\n",
      "868 0.21216964837011637\n",
      "869 0.21214286889698653\n",
      "870 0.21211627931563298\n",
      "871 0.21208967311915183\n",
      "872 0.21206293797673556\n",
      "873 0.21203645958222267\n",
      "874 0.21201007681845413\n",
      "875 0.21198372283564154\n",
      "876 0.21195742760542616\n",
      "877 0.21193130672011223\n",
      "878 0.21190513788313908\n",
      "879 0.21187919139978456\n",
      "880 0.21185349722814037\n",
      "881 0.21182784519362427\n",
      "882 0.21180213448682134\n",
      "883 0.2117766191555422\n",
      "884 0.21175123504626567\n",
      "885 0.21172586778963084\n",
      "886 0.21170044916681888\n",
      "887 0.21167490200027006\n",
      "888 0.21164938036614622\n",
      "889 0.21162410211805197\n",
      "890 0.21159877644795214\n",
      "891 0.21157340797683674\n",
      "892 0.211547525139146\n",
      "893 0.2115213849151722\n",
      "894 0.21149500869938867\n",
      "895 0.2114687327162848\n",
      "896 0.21144268866835828\n",
      "897 0.2114170688936068\n",
      "898 0.2113913390201501\n",
      "899 0.2113659341438568\n",
      "900 0.21134023043447256\n",
      "901 0.2113143700003888\n",
      "902 0.21128852924400648\n",
      "903 0.21126262129310971\n",
      "904 0.21123694527004785\n",
      "905 0.2112113929414733\n",
      "906 0.21118593481031545\n",
      "907 0.2111605976927285\n",
      "908 0.21113535982189985\n",
      "909 0.21110992523790179\n",
      "910 0.2110839720538894\n",
      "911 0.2110579250930205\n",
      "912 0.2110314911211013\n",
      "913 0.21100523673696406\n",
      "914 0.21097932031915842\n",
      "915 0.21095376210481012\n",
      "916 0.2109280427517155\n",
      "917 0.21090226723582386\n",
      "918 0.21087638133918046\n",
      "919 0.21085051575278965\n",
      "920 0.21082450278718814\n",
      "921 0.21079834568423725\n",
      "922 0.21077226575881677\n",
      "923 0.21074608262072594\n",
      "924 0.21071977188046898\n",
      "925 0.21069333347487654\n",
      "926 0.21066688194509592\n",
      "927 0.21064045251683386\n",
      "928 0.21061398183156294\n",
      "929 0.21058755379987026\n",
      "930 0.2105611556206482\n",
      "931 0.2105347642993924\n",
      "932 0.2105082838049777\n",
      "933 0.21048180734989205\n",
      "934 0.2104552332589709\n",
      "935 0.21042843052272228\n",
      "936 0.21040169842162454\n",
      "937 0.21037489449881025\n",
      "938 0.210348058577715\n",
      "939 0.21032122438107687\n",
      "940 0.21029443984356855\n",
      "941 0.21026742791690237\n",
      "942 0.21024019955004838\n",
      "943 0.2102132150364345\n",
      "944 0.21018657873237725\n",
      "945 0.2101597815215712\n",
      "946 0.21013292475077266\n",
      "947 0.21010589704073993\n",
      "948 0.21007909394747923\n",
      "949 0.210052685687039\n",
      "950 0.21002645727804328\n",
      "951 0.21000036873952513\n",
      "952 0.20997420376641335\n",
      "953 0.2099481057993381\n",
      "954 0.2099220941599501\n",
      "955 0.20989591923106804\n",
      "956 0.2098697814288394\n",
      "957 0.2098438665709983\n",
      "958 0.20981816614982715\n",
      "959 0.20979272651328823\n",
      "960 0.20976736871705756\n",
      "961 0.20974206841067086\n",
      "962 0.2097166187369292\n",
      "963 0.2096910183549184\n",
      "964 0.20966526473211772\n",
      "965 0.20963946227853553\n",
      "966 0.20961349904651497\n",
      "967 0.20958729874832693\n",
      "968 0.2095610978905804\n",
      "969 0.20953471906182777\n",
      "970 0.20950841555481242\n",
      "971 0.2094823168229224\n",
      "972 0.20945627526284866\n",
      "973 0.20943029720063233\n",
      "974 0.20940434710050404\n",
      "975 0.2093785669596312\n",
      "976 0.2093528021014803\n",
      "977 0.20932723751013588\n",
      "978 0.2093017128873779\n",
      "979 0.20927618142381968\n",
      "980 0.20925080433639737\n",
      "981 0.20922551136685807\n",
      "982 0.20920014314394442\n",
      "983 0.20917478234636325\n",
      "984 0.20914938392567475\n",
      "985 0.20912392812967487\n",
      "986 0.20909831061373288\n",
      "987 0.20907273784455663\n",
      "988 0.20904753483066363\n",
      "989 0.20902253458488348\n",
      "990 0.20899754202368323\n",
      "991 0.20897253364597865\n",
      "992 0.20894764039838667\n",
      "993 0.20892274652537246\n",
      "994 0.2088977233619154\n",
      "995 0.20887276980529498\n",
      "996 0.20884764140754003\n",
      "997 0.20882239228720065\n",
      "998 0.20879726143258287\n",
      "999 0.20877220681625203\n",
      "60.54255986213684\n",
      "tensor([[ 1.8566,  0.4259],\n",
      "        [ 1.6299,  0.9325],\n",
      "        [ 0.9755,  2.6126],\n",
      "        [ 1.9808,  4.1158],\n",
      "        [ 1.3132,  0.7383],\n",
      "        [ 1.2635,  1.5834],\n",
      "        [ 0.6576,  1.3773],\n",
      "        [ 2.6700,  1.8980],\n",
      "        [ 1.1976,  1.7512],\n",
      "        [ 0.2237,  1.6020],\n",
      "        [ 2.1847,  1.1461],\n",
      "        [ 1.0705,  2.6041],\n",
      "        [ 1.4688,  1.1289],\n",
      "        [ 1.5276,  3.0078],\n",
      "        [ 1.6594,  2.4523],\n",
      "        [ 1.7098,  0.6827],\n",
      "        [ 2.3471,  1.3818],\n",
      "        [ 1.7296,  4.0560],\n",
      "        [ 0.2629,  0.4042],\n",
      "        [-0.4819,  1.6622],\n",
      "        [ 1.6115,  1.2433],\n",
      "        [ 1.5534, -0.2225],\n",
      "        [ 1.0477,  1.1359],\n",
      "        [ 1.7710,  2.8273],\n",
      "        [ 2.4188,  0.7207],\n",
      "        [ 2.4385,  2.9653],\n",
      "        [ 0.9649,  1.1049],\n",
      "        [ 1.9925,  2.5436],\n",
      "        [ 1.7258,  0.8557],\n",
      "        [ 0.3917,  1.0614],\n",
      "        [ 0.1048,  2.5028],\n",
      "        [ 0.8926,  1.1518],\n",
      "        [ 1.5282,  0.8772],\n",
      "        [ 1.0501,  1.6023],\n",
      "        [ 1.4313,  2.8467],\n",
      "        [ 0.9078,  1.0686],\n",
      "        [ 1.5175,  2.4806],\n",
      "        [ 0.7535,  1.0754],\n",
      "        [ 0.8227,  1.1149],\n",
      "        [ 0.5385,  1.7207],\n",
      "        [ 1.7908,  2.2788],\n",
      "        [ 1.1651,  3.0895],\n",
      "        [ 3.0265,  1.7430],\n",
      "        [ 1.5700,  0.2410],\n",
      "        [ 1.9292,  1.2219],\n",
      "        [ 1.4169,  1.0856],\n",
      "        [ 1.8043,  0.8525],\n",
      "        [ 1.0755,  0.2615],\n",
      "        [ 0.8055,  0.3587],\n",
      "        [ 1.5681,  1.5628],\n",
      "        [ 0.8658,  0.9462],\n",
      "        [ 1.2213,  0.4943],\n",
      "        [ 0.0050,  1.4517],\n",
      "        [ 1.8473,  2.2461],\n",
      "        [ 0.3665,  1.0977],\n",
      "        [ 1.5945,  1.2168],\n",
      "        [ 0.9198,  1.6841],\n",
      "        [ 1.3480,  2.7342],\n",
      "        [ 1.3705,  1.2248],\n",
      "        [ 1.5177,  2.0514],\n",
      "        [ 1.1850,  0.0927],\n",
      "        [ 1.4196,  0.5586],\n",
      "        [ 0.5719,  1.7727],\n",
      "        [ 1.2819, -0.0526],\n",
      "        [ 1.9645,  1.0607],\n",
      "        [ 0.4223,  1.3251],\n",
      "        [ 1.2190,  2.0207],\n",
      "        [ 3.0086,  2.6921],\n",
      "        [ 0.5338,  1.4108],\n",
      "        [ 0.9948,  1.0725],\n",
      "        [ 0.4771,  0.3259],\n",
      "        [ 2.4272,  0.9792],\n",
      "        [ 0.8856,  0.9155],\n",
      "        [ 0.3192,  0.8061],\n",
      "        [ 1.9590,  2.2934],\n",
      "        [ 2.4318, -0.1071],\n",
      "        [ 1.7363,  1.8501],\n",
      "        [ 1.6872,  1.1978],\n",
      "        [ 1.0320,  2.7650],\n",
      "        [ 1.5466,  0.3630],\n",
      "        [ 2.8906,  2.9140],\n",
      "        [ 1.6971,  2.6028],\n",
      "        [ 0.3825,  2.8320],\n",
      "        [ 0.5186,  0.5875],\n",
      "        [ 1.0447,  0.2819],\n",
      "        [ 1.7255,  2.6602],\n",
      "        [ 1.0714,  1.4255],\n",
      "        [ 2.1417,  3.4593],\n",
      "        [ 2.0139,  1.2363],\n",
      "        [ 2.1012,  0.5890],\n",
      "        [ 1.0397,  2.6020],\n",
      "        [ 1.5453,  3.3291],\n",
      "        [ 1.7406,  2.9297],\n",
      "        [ 1.4023,  2.1014],\n",
      "        [ 0.3683,  1.9453],\n",
      "        [ 1.2272,  3.2748],\n",
      "        [ 1.5779,  0.3347],\n",
      "        [ 1.4717,  3.4478],\n",
      "        [ 1.4865,  0.3621],\n",
      "        [ 1.8100,  3.7169],\n",
      "        [ 1.5702,  1.4735],\n",
      "        [ 0.9365,  0.6995],\n",
      "        [ 1.6835,  0.3888],\n",
      "        [ 2.9463,  2.8490],\n",
      "        [ 0.0191,  1.8849],\n",
      "        [ 1.4101,  0.8177],\n",
      "        [ 1.5244,  1.7392],\n",
      "        [ 2.1372,  1.7686],\n",
      "        [ 1.7219,  3.3415],\n",
      "        [ 0.3882,  2.0759],\n",
      "        [ 0.3870,  1.0347],\n",
      "        [ 1.3332,  0.9169],\n",
      "        [ 2.0845,  3.0458],\n",
      "        [ 1.6809,  3.6082],\n",
      "        [-0.1025,  1.7914],\n",
      "        [ 1.6555,  0.7384],\n",
      "        [ 0.6531,  0.4107],\n",
      "        [ 1.5915,  0.4990],\n",
      "        [-0.3840,  1.8355],\n",
      "        [ 0.4364,  1.3386],\n",
      "        [ 2.1848,  0.1130],\n",
      "        [ 2.4075,  2.1866],\n",
      "        [ 1.0290,  1.6503],\n",
      "        [ 1.4515,  1.9957],\n",
      "        [ 2.0830,  1.9729],\n",
      "        [ 1.4639,  1.3392],\n",
      "        [ 2.6915,  3.8823],\n",
      "        [ 1.1102,  0.4715],\n",
      "        [ 1.0849,  1.1697],\n",
      "        [ 1.1275,  0.3607],\n",
      "        [ 2.0551,  0.6851],\n",
      "        [ 2.2975,  2.1196],\n",
      "        [ 2.2032,  0.4756],\n",
      "        [ 1.1769,  3.5052],\n",
      "        [ 0.4193,  0.5914],\n",
      "        [ 0.8806,  0.7058],\n",
      "        [ 0.6450,  3.1524],\n",
      "        [ 1.2425,  2.3567],\n",
      "        [ 1.1990,  2.7112],\n",
      "        [ 1.1715,  2.6654],\n",
      "        [ 0.6872,  2.2269],\n",
      "        [ 1.2859,  1.6162],\n",
      "        [ 0.3523,  0.7883],\n",
      "        [ 2.3381,  1.9435],\n",
      "        [ 0.9228,  1.7324],\n",
      "        [ 2.3672,  2.4410],\n",
      "        [ 1.3260,  0.9945],\n",
      "        [ 0.4683,  0.7643],\n",
      "        [ 2.3288,  2.0266],\n",
      "        [ 2.1577,  1.7307],\n",
      "        [ 1.2246, -0.0923],\n",
      "        [ 2.5724,  2.8698],\n",
      "        [ 0.2462,  0.8930],\n",
      "        [ 1.0868,  2.1390],\n",
      "        [ 1.0151,  1.8748],\n",
      "        [ 1.3285,  1.2455],\n",
      "        [ 0.8044,  0.6453],\n",
      "        [ 1.5930,  0.6442],\n",
      "        [ 1.1830,  1.2169],\n",
      "        [ 0.7135,  1.6890],\n",
      "        [ 1.9408,  0.0680],\n",
      "        [ 1.5507,  2.0152],\n",
      "        [ 0.3545,  0.0804],\n",
      "        [ 2.0595,  1.0621],\n",
      "        [ 0.7651,  1.0662],\n",
      "        [ 1.1079,  0.4168],\n",
      "        [-0.2194,  2.1476],\n",
      "        [ 0.7780,  1.7325],\n",
      "        [ 1.2566,  0.6375],\n",
      "        [ 0.8492,  1.9589],\n",
      "        [ 2.0858,  1.8002],\n",
      "        [ 0.1053,  1.4235],\n",
      "        [ 0.6168,  0.4803],\n",
      "        [ 1.3188,  2.6265],\n",
      "        [ 1.5374,  1.5355],\n",
      "        [ 2.4531,  2.5261],\n",
      "        [ 1.0737,  0.9544],\n",
      "        [ 1.3131,  0.2850],\n",
      "        [ 0.8514,  2.5508],\n",
      "        [ 2.0363,  2.7872],\n",
      "        [ 1.1637,  1.8339],\n",
      "        [ 1.4216,  0.1596],\n",
      "        [ 1.6307, -0.0107],\n",
      "        [ 1.0676,  2.4585],\n",
      "        [ 0.8002,  1.4745],\n",
      "        [ 1.7805,  3.0426],\n",
      "        [ 1.0171,  0.3906],\n",
      "        [ 0.8581,  3.3350],\n",
      "        [-0.3961,  1.6222],\n",
      "        [ 1.7234,  1.3218],\n",
      "        [ 0.4594,  0.7275],\n",
      "        [ 0.7639,  1.2728],\n",
      "        [ 2.2377,  2.9719],\n",
      "        [ 0.6690,  0.9804],\n",
      "        [ 0.6842,  1.3580],\n",
      "        [ 0.4070,  0.1642],\n",
      "        [ 1.5788,  0.2353],\n",
      "        [ 0.2266,  2.1066],\n",
      "        [ 1.6601,  0.5784],\n",
      "        [ 1.2622,  0.3731],\n",
      "        [ 0.9342,  1.5135],\n",
      "        [ 0.7913,  1.1758],\n",
      "        [ 1.1257,  0.3299],\n",
      "        [ 1.0114,  1.0549],\n",
      "        [ 0.5081,  1.8419],\n",
      "        [ 2.6089,  3.1486],\n",
      "        [ 2.2197,  1.0570],\n",
      "        [ 0.3497,  0.1952],\n",
      "        [ 0.7350,  0.5110],\n",
      "        [ 1.8193,  1.5107],\n",
      "        [ 2.0123,  0.4625],\n",
      "        [ 0.0759,  1.2146],\n",
      "        [ 1.6904,  2.4566],\n",
      "        [ 2.1815,  1.9589],\n",
      "        [ 2.5833,  1.6628],\n",
      "        [ 1.9643,  2.6794],\n",
      "        [ 0.7540,  0.4114],\n",
      "        [ 0.4530,  2.3736],\n",
      "        [ 0.8763,  1.3839],\n",
      "        [ 0.7040,  2.2290],\n",
      "        [ 1.5627,  1.4540],\n",
      "        [ 1.3958,  1.4792],\n",
      "        [ 1.4569,  3.4931],\n",
      "        [ 1.7649,  0.1633],\n",
      "        [ 0.4404,  0.5177],\n",
      "        [ 1.7091,  0.0824],\n",
      "        [ 0.3749,  2.7903],\n",
      "        [ 0.7970,  1.9694],\n",
      "        [ 0.6083,  0.7757],\n",
      "        [ 0.4591,  1.9018],\n",
      "        [ 1.7953,  0.9817],\n",
      "        [ 0.9663,  1.0573],\n",
      "        [ 0.4498,  1.7776],\n",
      "        [ 0.1039,  1.7064],\n",
      "        [ 0.8180,  0.7638],\n",
      "        [ 0.9326,  1.1727],\n",
      "        [ 0.7768,  0.8705],\n",
      "        [ 1.8499,  3.9056],\n",
      "        [ 1.5899,  3.0031],\n",
      "        [ 0.3563,  1.6034]], dtype=torch.float64, grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# step 2. train the model\n",
    "# initialize the optimizer\n",
    "optimizer = torch.optim.SGD([alpha_matrix, mu_matrix, sd_matrix], lr=0.6)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=170, gamma=0.84)\n",
    "\n",
    "# train the model\n",
    "start = time.time()\n",
    "for k in range(1000):\n",
    "    \"\"\"alpha = torch.matmul(X_train[:, 2:3], alpha_matrix)\n",
    "    mu = torch.matmul(X_train[:, [0, 4, 6]], mu_matrix)\n",
    "    sd = torch.abs(torch.matmul(torch.abs(X_train[:, [0, 1, 6]]), sd_matrix))\"\"\"\n",
    "\n",
    "    alpha = torch.matmul(X_train, alpha_matrix)\n",
    "    mu = torch.matmul(X_train, mu_matrix)\n",
    "    sd = torch.abs(torch.matmul(torch.abs(X_train), sd_matrix))\n",
    "\n",
    "    pi = torch.softmax(alpha, dim=1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = WDL(y_train, q_vec, mu, sd, pi)\n",
    "    print(k, loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "print(mu)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6073d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.66676478e-01 -2.84067649e-01]\n",
      " [ 2.96840067e-01 -1.44553624e+00]\n",
      " [ 1.38995844e+00  5.06455550e-01]\n",
      " [ 1.12654493e+00  4.77331162e-01]\n",
      " [ 9.64291138e-01  1.58315217e-01]\n",
      " [ 1.81584360e-01  9.39345539e-01]\n",
      " [ 1.25845916e+00  2.35090734e-01]\n",
      " [ 5.91216707e-01  7.41017517e-01]\n",
      " [ 3.45591939e-01  1.25174015e+00]\n",
      " [ 2.51078522e-01 -5.05201003e-01]\n",
      " [-1.21620893e-01  8.20351780e-01]\n",
      " [ 7.35562548e-01  8.44545562e-01]\n",
      " [ 4.86298687e-01  1.71218464e+00]\n",
      " [ 4.67980513e-01  1.39678620e+00]\n",
      " [ 5.06183345e-01  8.41167563e-01]\n",
      " [ 2.36277541e-01  7.46228737e-01]\n",
      " [ 4.38339687e-01  1.17203483e-01]\n",
      " [ 6.32575823e-01  1.34099146e+00]\n",
      " [ 2.30677905e-01  1.51226974e-01]\n",
      " [ 9.95972070e-01  1.62690942e-01]\n",
      " [ 7.01800142e-01 -8.03170859e-02]\n",
      " [ 6.60889340e-01 -5.47164647e-01]\n",
      " [ 1.14072911e+00  8.68564505e-01]\n",
      " [ 1.01782373e+00  7.42340494e-01]\n",
      " [ 4.54636171e-01  8.62823627e-01]\n",
      " [ 4.08696982e-01  6.08927207e-01]\n",
      " [ 1.08478362e+00  5.49710235e-01]\n",
      " [ 1.07833246e+00  2.42432466e-01]\n",
      " [ 6.86554632e-01  6.36729345e-01]\n",
      " [ 8.31001655e-01 -6.16224043e-01]\n",
      " [ 5.88617060e-01  8.99398425e-02]\n",
      " [ 1.50102568e+00  8.14898376e-01]\n",
      " [ 3.87048183e-01 -3.55325288e-01]\n",
      " [ 1.13123140e+00  8.99971807e-01]\n",
      " [ 6.87263283e-01  2.18028769e-02]\n",
      " [ 9.04245361e-01  4.31148033e-01]\n",
      " [ 1.10140109e+00  5.67479771e-01]\n",
      " [ 1.01522451e+00  1.04639028e+00]\n",
      " [ 6.65714164e-01  3.00160464e-01]\n",
      " [ 1.01585280e+00  1.98427135e-01]\n",
      " [ 5.31670501e-01 -3.09686360e-01]\n",
      " [ 8.67015803e-01  9.55342337e-01]\n",
      " [ 8.11512036e-01 -2.00464207e-01]\n",
      " [ 8.65373617e-01  1.84393484e-01]\n",
      " [ 8.43953797e-01 -5.28067403e-01]\n",
      " [ 5.52101821e-01  1.25271640e-01]\n",
      " [ 2.89013210e-01 -1.07190006e+00]\n",
      " [ 1.09435265e+00 -3.47412938e-01]\n",
      " [ 6.29817327e-01 -7.50613173e-01]\n",
      " [ 7.37000443e-01  5.46739517e-01]\n",
      " [ 1.17558789e+00 -2.93839427e-01]\n",
      " [ 1.16549882e+00 -3.59361066e-02]\n",
      " [ 8.95669615e-01 -3.63883718e-01]\n",
      " [ 7.96241922e-02 -1.31680865e+00]\n",
      " [ 1.23603870e-01  1.96191325e-01]\n",
      " [ 1.22074526e+00  1.56017644e+00]\n",
      " [ 1.95661720e-01 -1.00570909e+00]\n",
      " [ 7.25354014e-01  3.57140082e-01]\n",
      " [ 1.75805851e-01 -4.22173371e-01]\n",
      " [ 1.49191869e+00  1.18305408e+00]\n",
      " [ 7.48938247e-01  6.42749103e-01]\n",
      " [ 2.94926917e-01 -2.64227470e-01]\n",
      " [ 1.13953699e+00  3.01193572e-01]\n",
      " [ 1.08055152e+00 -4.29461638e-01]\n",
      " [ 5.06812633e-01  2.25363427e-01]\n",
      " [ 7.03806123e-01  8.50291291e-01]\n",
      " [ 1.88491446e-01  1.81061789e-02]\n",
      " [ 7.40992629e-01  1.64281756e+00]\n",
      " [ 1.16856783e+00  4.26076467e-02]\n",
      " [ 9.85874644e-01 -5.21718817e-01]\n",
      " [ 5.91108790e-01 -8.44907551e-01]\n",
      " [ 1.75734326e-01 -6.27463220e-01]\n",
      " [ 1.06244483e-01 -6.83473832e-01]\n",
      " [ 1.04618286e+00 -2.26481386e-01]\n",
      " [ 3.59630791e-01 -1.04965029e-01]\n",
      " [ 1.55938289e+00  1.11636906e+00]\n",
      " [ 1.04626908e+00  1.06453088e+00]\n",
      " [ 9.24362425e-01  8.90742065e-01]\n",
      " [ 6.75130799e-01 -1.03779868e+00]\n",
      " [ 1.85299569e-02 -4.33882016e-01]\n",
      " [ 6.84710744e-01  1.45834775e+00]\n",
      " [ 2.54253637e-01 -1.29180601e+00]\n",
      " [ 4.07006495e-01  6.23413119e-03]\n",
      " [ 7.82031571e-01  1.03727767e-01]\n",
      " [ 5.61378113e-01  3.54509100e-01]\n",
      " [ 7.63771599e-01 -4.75967957e-01]\n",
      " [ 1.25894842e-01 -6.39451523e-01]\n",
      " [ 9.60234698e-01  7.39446804e-01]\n",
      " [ 1.29654195e-01 -2.27918569e-01]\n",
      " [ 4.30775187e-01  6.41942820e-02]\n",
      " [ 1.25247739e+00  7.66114575e-01]\n",
      " [ 7.43694307e-01  1.28410146e+00]\n",
      " [ 3.35126681e-01  3.61030447e-01]\n",
      " [ 1.10275749e+00  5.97852405e-01]\n",
      " [ 8.84030559e-01 -3.15058034e-01]\n",
      " [ 4.99227457e-01 -8.19588427e-01]\n",
      " [ 6.21525167e-01  7.49892960e-01]\n",
      " [ 1.54928190e+00  1.53184161e-01]\n",
      " [ 9.72581581e-01  1.33167750e-02]\n",
      " [ 1.15582349e+00  3.47621182e-01]\n",
      " [ 1.14523285e+00  9.62398211e-01]\n",
      " [ 7.48075202e-01 -2.37518104e-01]\n",
      " [ 1.28694745e+00  4.06295915e-01]\n",
      " [ 8.65770184e-01  7.79061944e-01]\n",
      " [ 3.82459414e-01  1.23510854e+00]\n",
      " [ 5.12525566e-01  2.89482338e-01]\n",
      " [ 4.92137645e-01 -1.90297690e-01]\n",
      " [ 5.99636808e-01  6.57056689e-01]\n",
      " [ 5.65666813e-01 -9.21166761e-02]\n",
      " [ 5.14925486e-01 -6.45005554e-01]\n",
      " [ 1.38700937e+00  7.24352583e-01]\n",
      " [-2.91556640e-01  1.22267498e-03]\n",
      " [ 1.00789098e+00  4.71142899e-02]\n",
      " [ 1.27631398e+00  1.55555105e+00]\n",
      " [ 3.01702146e-01 -1.54098449e-01]\n",
      " [ 3.17456944e-01  3.97084103e-01]\n",
      " [-1.51975399e-02 -3.43171321e-01]\n",
      " [ 7.01642388e-01 -1.03296762e-01]\n",
      " [ 7.17833413e-01  3.36172815e-01]\n",
      " [ 7.05864116e-01 -6.18027358e-01]\n",
      " [ 8.31185646e-01  1.53345455e-01]\n",
      " [ 7.40407683e-01  7.89430620e-02]\n",
      " [ 8.49052682e-01  2.32465129e-01]\n",
      " [ 8.75653589e-01 -2.02181925e-01]\n",
      " [ 5.30132514e-01 -9.85146928e-01]\n",
      " [ 8.85088748e-01  5.85234776e-01]\n",
      " [ 3.47610589e-01  4.50786416e-01]\n",
      " [ 5.58939258e-01 -2.74148197e-01]\n",
      " [ 5.36718093e-01  6.16678292e-01]\n",
      " [ 5.77342529e-01  5.53546644e-01]\n",
      " [ 5.66515840e-01  1.09453347e+00]\n",
      " [ 1.24234962e+00  8.34868423e-01]\n",
      " [ 2.09940518e-01  6.00888479e-01]\n",
      " [ 7.92949778e-01  1.13396364e+00]\n",
      " [ 6.60608827e-01  4.18421525e-01]\n",
      " [ 2.07241985e-01 -1.66432507e-01]\n",
      " [ 1.44986611e+00  5.72117508e-01]\n",
      " [ 7.45340023e-01  6.29291813e-01]\n",
      " [ 1.10161484e+00  2.13710845e-01]\n",
      " [ 6.46301615e-01 -2.32430173e-01]\n",
      " [ 6.51297711e-01  1.37848394e-01]\n",
      " [ 6.40929321e-01 -1.20804982e-01]\n",
      " [ 1.08423609e+00  2.49683861e-01]\n",
      " [ 5.82227223e-01  1.22327496e+00]\n",
      " [ 4.98347968e-01  7.60460868e-01]\n",
      " [ 1.15804710e+00  2.09228087e-01]\n",
      " [ 2.88085055e-01 -3.28280300e-01]\n",
      " [ 1.42332638e+00  1.63251559e+00]\n",
      " [ 7.52051555e-01  5.92421348e-01]\n",
      " [ 7.20121917e-01  1.61220341e+00]\n",
      " [ 7.99449815e-01  8.17175215e-01]\n",
      " [ 9.19828740e-01  6.60250314e-01]\n",
      " [ 5.99812705e-01 -6.11859543e-01]\n",
      " [ 8.82314093e-01  8.97241013e-01]\n",
      " [ 1.24238044e+00  3.57607658e-02]\n",
      " [-6.95916981e-03  1.99153598e-01]\n",
      " [ 1.09817454e+00  3.64282560e-01]\n",
      " [ 1.23657197e+00  3.06494637e-01]\n",
      " [ 5.57262463e-01  1.52499418e+00]\n",
      " [ 8.23646738e-01  1.02045525e+00]\n",
      " [ 1.31990558e-01  7.55791700e-02]\n",
      " [ 7.44299676e-01 -1.29689196e-01]\n",
      " [ 5.13592588e-01  1.14173354e+00]\n",
      " [ 1.80944680e-02 -4.77484029e-01]\n",
      " [ 7.10823894e-02 -2.23307965e-01]\n",
      " [ 3.45978566e-01 -7.29805613e-01]\n",
      " [ 7.98330881e-01  1.71631671e-01]\n",
      " [ 7.94071063e-01  7.31566472e-01]\n",
      " [ 6.63134921e-01  1.94366169e-01]\n",
      " [ 3.17653757e-01 -1.65667211e-01]\n",
      " [ 6.68188656e-01 -6.32084754e-01]\n",
      " [ 9.85000640e-01  1.00923036e-01]\n",
      " [ 3.34016149e-01  1.17589228e+00]\n",
      " [ 2.54091858e-01  2.99985261e-02]\n",
      " [ 4.58324580e-01 -1.10817072e+00]\n",
      " [ 1.02012950e+00  8.58916459e-01]\n",
      " [ 6.11897241e-01  5.61174141e-02]\n",
      " [ 5.41188887e-01  6.19114087e-01]\n",
      " [ 9.63490376e-01  1.48607041e-01]\n",
      " [ 1.01993478e+00  7.72895490e-01]\n",
      " [ 1.29400794e+00  1.31681406e+00]\n",
      " [ 6.64071923e-01 -1.27399390e-01]\n",
      " [ 2.48569669e-01  1.16469739e-01]\n",
      " [ 7.24721559e-01  3.51877869e-01]\n",
      " [ 1.03627876e+00  6.76607273e-02]\n",
      " [ 5.22978607e-01  2.22526362e-01]\n",
      " [ 1.58871027e-01  1.05429315e+00]\n",
      " [ 8.35094693e-01 -2.90359001e-01]\n",
      " [ 1.07409402e+00 -2.00498107e-02]\n",
      " [ 4.95702307e-01  4.60251995e-01]\n",
      " [ 9.52794871e-01  3.36471947e-01]\n",
      " [ 3.08897096e-01 -3.20022272e-02]\n",
      " [ 1.24162737e+00  1.47422675e+00]\n",
      " [ 2.68154031e-01  1.87097161e-01]\n",
      " [ 6.58581935e-01  1.53561498e+00]\n",
      " [-6.79319005e-02  1.78451105e-01]\n",
      " [ 1.18532207e+00 -1.34637966e-01]\n",
      " [ 9.95882893e-01  5.50174194e-01]\n",
      " [ 1.37454171e+00  1.06077528e+00]\n",
      " [ 1.01045271e+00  1.40390501e-01]\n",
      " [ 2.41837929e-01 -7.55437672e-01]\n",
      " [ 5.62039501e-01 -8.09613186e-02]\n",
      " [ 9.12755961e-01 -5.14000783e-01]\n",
      " [ 9.85800665e-01  8.47859688e-01]\n",
      " [ 6.82249724e-01 -8.21838139e-02]\n",
      " [ 3.59048923e-01  1.39609942e+00]\n",
      " [ 6.50717304e-01 -6.44007456e-01]\n",
      " [ 1.29203224e+00  1.21823371e+00]\n",
      " [ 1.28462079e+00  6.85824115e-01]\n",
      " [ 4.63706973e-01  1.61536951e+00]\n",
      " [ 1.04238298e+00  2.52454985e-01]\n",
      " [ 6.53019376e-01  5.95785805e-01]\n",
      " [ 4.59195457e-01  1.26417521e+00]\n",
      " [ 1.17509090e+00 -4.19061386e-01]\n",
      " [ 8.57042395e-01 -2.85103080e-01]\n",
      " [-2.47269825e-01  6.04402158e-01]\n",
      " [ 8.36254927e-01  4.43099211e-01]\n",
      " [ 1.25809887e+00  9.09069473e-01]\n",
      " [ 7.31379238e-01  1.81333254e+00]\n",
      " [ 1.29079190e+00  1.15323554e+00]\n",
      " [ 1.00073786e+00  1.91726358e-02]\n",
      " [ 1.05743365e+00  1.21282788e+00]\n",
      " [ 1.21164665e+00  1.05418760e+00]\n",
      " [ 1.50318171e+00  1.39506095e+00]\n",
      " [ 5.43517838e-01  5.10524798e-01]\n",
      " [ 1.30131420e+00  1.42141064e+00]\n",
      " [ 9.94610713e-01  2.19764596e-01]\n",
      " [ 5.16476813e-01 -9.02186235e-01]\n",
      " [ 2.09295980e-01 -4.80751507e-01]\n",
      " [ 1.69175457e-01 -2.03171049e-01]\n",
      " [ 1.36661816e+00  4.31372372e-01]\n",
      " [ 9.46321427e-01  4.43904586e-01]\n",
      " [ 7.59925918e-01  6.67377916e-01]\n",
      " [ 2.28636170e-01  3.10026053e-02]\n",
      " [ 8.95990241e-01  2.88184026e-01]\n",
      " [ 9.14892596e-01  2.35132156e-01]\n",
      " [ 3.90205398e-01 -7.23189725e-01]\n",
      " [ 1.34508092e+00  1.03968020e+00]\n",
      " [ 1.38328364e+00  4.93955953e-01]\n",
      " [ 7.42534280e-01 -5.02123167e-01]]\n",
      "[[ 0.49559938 -0.42316504]\n",
      " [-0.11273809 -0.51299145]\n",
      " [ 0.53740975 -0.58132721]\n",
      " [ 0.6611832  -0.60083302]\n",
      " [ 0.41861169 -0.7265914 ]\n",
      " [ 0.30342228 -0.31602184]\n",
      " [ 0.22355985 -0.13575857]\n",
      " [ 0.64828661 -0.37668027]\n",
      " [ 0.29809458 -0.20990768]\n",
      " [ 0.26617435 -0.39212737]\n",
      " [-0.0106511  -0.11740091]\n",
      " [ 0.4848837  -0.63733094]\n",
      " [ 0.16533745 -0.16037671]\n",
      " [ 0.40529704 -0.49730716]\n",
      " [ 0.51862553 -0.66086002]\n",
      " [ 0.35758847 -0.39726488]\n",
      " [ 0.16958399  0.17571125]\n",
      " [ 0.50038628 -0.53234472]\n",
      " [ 0.10209924  0.19542257]\n",
      " [ 0.51735235 -0.64257661]\n",
      " [ 0.4504563  -0.11133658]\n",
      " [ 0.36494302 -0.52003668]\n",
      " [ 0.63964192 -0.35646007]\n",
      " [ 0.54462625 -0.41941512]\n",
      " [ 0.49937078 -0.61971084]\n",
      " [ 0.22353143  0.09889857]\n",
      " [ 0.63309548 -0.24555241]\n",
      " [ 0.29558645 -0.5824893 ]\n",
      " [ 0.69338944 -0.60096936]\n",
      " [ 0.1632121  -0.42089355]\n",
      " [ 0.21515413  0.22136791]\n",
      " [ 0.62175942 -0.71450603]\n",
      " [ 0.36651746 -0.53761909]\n",
      " [ 0.55927784 -0.22021982]\n",
      " [ 0.42888595 -0.08504471]\n",
      " [ 0.46135947 -0.20743218]\n",
      " [ 0.6952901  -0.39525871]\n",
      " [ 0.59738716 -0.56594342]\n",
      " [ 0.15679041  0.22354354]\n",
      " [ 0.49334929 -0.17514485]\n",
      " [ 0.36541468 -0.21335203]\n",
      " [ 0.62828683 -0.28623526]\n",
      " [-0.02287179 -0.41938633]\n",
      " [ 0.44018424 -0.03163113]\n",
      " [ 0.22723759 -0.26190464]\n",
      " [ 0.27672775  0.10354546]\n",
      " [ 0.07547295 -0.46742246]\n",
      " [ 0.31751214  0.06347208]\n",
      " [ 0.12580113 -0.42109011]\n",
      " [ 0.10359268 -0.38636539]\n",
      " [ 0.34824801 -0.60450282]\n",
      " [ 0.11477538  0.00624238]\n",
      " [ 0.42653103 -0.52882191]\n",
      " [-0.19191502 -0.18583193]\n",
      " [ 0.30668293 -0.26597864]\n",
      " [ 0.25383832 -0.15811977]\n",
      " [ 0.04423507 -0.59601068]\n",
      " [ 0.19542204  0.2173057 ]\n",
      " [ 0.22899594 -0.20460463]\n",
      " [ 0.5346223  -0.42211085]\n",
      " [ 0.28188993  0.06911778]\n",
      " [ 0.1664481   0.11249797]\n",
      " [ 0.68852429 -0.5970193 ]\n",
      " [ 0.35584645 -0.59352485]\n",
      " [ 0.3056346  -0.02327684]\n",
      " [ 0.55929398 -0.14738451]\n",
      " [ 0.21930136  0.02766436]\n",
      " [ 0.41176293 -0.42712858]\n",
      " [ 0.5188413  -0.45624665]\n",
      " [ 0.3932824  -0.63284927]\n",
      " [ 0.2104313  -0.56016724]\n",
      " [ 0.1248943  -0.01972888]\n",
      " [ 0.00772054  0.06012507]\n",
      " [ 0.4396402  -0.57836489]\n",
      " [-0.01960955  0.34937622]\n",
      " [ 0.59049875 -0.70611246]\n",
      " [ 0.33327933 -0.0626968 ]\n",
      " [ 0.71202349 -0.56774853]\n",
      " [ 0.09639431 -0.05362052]\n",
      " [-0.14905849  0.35692606]\n",
      " [ 0.5543358  -0.3329698 ]\n",
      " [-0.03116528 -0.56070051]\n",
      " [ 0.26034858 -0.02968439]\n",
      " [ 0.47980526 -0.11830403]\n",
      " [ 0.56451331 -0.24332724]\n",
      " [ 0.37550416 -0.58681733]\n",
      " [-0.00676186  0.12456159]\n",
      " [ 0.50432461 -0.16061447]\n",
      " [ 0.10940638  0.1556402 ]\n",
      " [ 0.2962948   0.068415  ]\n",
      " [ 0.67875763 -0.57769091]\n",
      " [ 0.40882303 -0.04902712]\n",
      " [-0.01590624  0.04940175]\n",
      " [ 0.5092389  -0.6269056 ]\n",
      " [ 0.48173038 -0.66990613]\n",
      " [ 0.20633697 -0.04017555]\n",
      " [ 0.07452077 -0.11761544]\n",
      " [ 0.30294373 -0.01683339]\n",
      " [ 0.40154858 -0.26307586]\n",
      " [ 0.45412096 -0.67871955]\n",
      " [ 0.56851719 -0.41164033]\n",
      " [ 0.15722109 -0.68921435]\n",
      " [ 0.50823849 -0.45417635]\n",
      " [ 0.45474047 -0.20838816]\n",
      " [ 0.36828338 -0.21776212]\n",
      " [ 0.59358815 -0.37080274]\n",
      " [ 0.3035391   0.00547207]\n",
      " [ 0.18446989 -0.00399766]\n",
      " [ 0.48157655 -0.3537203 ]\n",
      " [ 0.17221864 -0.56084876]\n",
      " [ 0.66762229 -0.72196473]\n",
      " [-0.19798926  0.20968848]\n",
      " [ 0.36382001 -0.56478524]\n",
      " [ 0.09418812 -0.11867374]\n",
      " [ 0.118714    0.2146226 ]\n",
      " [-0.14502552  0.01143056]\n",
      " [-0.04912467  0.22286247]\n",
      " [ 0.45950699 -0.13866452]\n",
      " [ 0.4480177  -0.01685609]\n",
      " [ 0.36114537 -0.63467299]\n",
      " [ 0.51348198 -0.2000975 ]\n",
      " [ 0.28120956 -0.55411305]\n",
      " [ 0.36919354 -0.5767187 ]\n",
      " [ 0.16455387 -0.41392134]\n",
      " [ 0.15535219 -0.38477194]\n",
      " [ 0.50170948 -0.36931356]\n",
      " [ 0.47247057 -0.41630854]\n",
      " [ 0.49267018 -0.62129362]\n",
      " [-0.13802516 -0.16937493]\n",
      " [ 0.58108258 -0.71167046]\n",
      " [ 0.52533558 -0.21531913]\n",
      " [ 0.70335953 -0.54272162]\n",
      " [ 0.35587192 -0.29326459]\n",
      " [ 0.42878298 -0.64927316]\n",
      " [ 0.43234928 -0.00346125]\n",
      " [ 0.05351788  0.1627154 ]\n",
      " [ 0.60927187 -0.5931989 ]\n",
      " [ 0.70199561 -0.64486815]\n",
      " [ 0.55515616 -0.77649789]\n",
      " [ 0.39075883 -0.16050027]\n",
      " [ 0.29526561 -0.38894183]\n",
      " [ 0.31299614 -0.48127492]\n",
      " [ 0.46109125 -0.72192205]\n",
      " [ 0.48535949 -0.66813958]\n",
      " [-0.1931408  -0.06998269]\n",
      " [ 0.22824911 -0.36539306]\n",
      " [ 0.27870983 -0.67577384]\n",
      " [ 0.39206274 -0.25191809]\n",
      " [ 0.25917209  0.1239459 ]\n",
      " [ 0.43318085 -0.42709436]\n",
      " [ 0.30054519 -0.22337457]\n",
      " [ 0.42781394 -0.41046262]\n",
      " [ 0.30429961 -0.43334599]\n",
      " [ 0.62666855 -0.74141742]\n",
      " [ 0.53970993 -0.57839261]\n",
      " [ 0.12199669 -0.00292138]\n",
      " [ 0.60216717 -0.27019011]\n",
      " [ 0.59000879 -0.40343602]\n",
      " [ 0.33151899 -0.22303921]\n",
      " [ 0.14137494 -0.1470847 ]\n",
      " [ 0.26711232 -0.21707255]\n",
      " [ 0.4942152  -0.30180421]\n",
      " [ 0.54739518 -0.36265005]\n",
      " [ 0.02254961  0.15855072]\n",
      " [-0.09033077  0.22284887]\n",
      " [ 0.15214264 -0.12263812]\n",
      " [ 0.43669585 -0.03725678]\n",
      " [ 0.53198714 -0.10335555]\n",
      " [ 0.37976344  0.03028866]\n",
      " [ 0.21263108  0.0693179 ]\n",
      " [ 0.34116961 -0.45498975]\n",
      " [ 0.46045626 -0.76427701]\n",
      " [ 0.24367059 -0.13112219]\n",
      " [ 0.0456286   0.17566192]\n",
      " [ 0.06451383 -0.45424609]\n",
      " [ 0.47450767 -0.06296749]\n",
      " [ 0.26833689 -0.3912188 ]\n",
      " [ 0.09661894 -0.08016274]\n",
      " [ 0.64438186 -0.39009662]\n",
      " [ 0.56406629 -0.3748542 ]\n",
      " [ 0.49533955 -0.2264499 ]\n",
      " [ 0.44168894 -0.12437076]\n",
      " [ 0.3361418  -0.11800676]\n",
      " [ 0.45855453 -0.08355237]\n",
      " [ 0.63365754 -0.49620922]\n",
      " [ 0.01567605  0.33762128]\n",
      " [ 0.18470684 -0.43108932]\n",
      " [ 0.44685263 -0.08330259]\n",
      " [ 0.4790291  -0.35331743]\n",
      " [-0.00756504  0.33209814]\n",
      " [ 0.61661864 -0.71013491]\n",
      " [ 0.12868256  0.12541233]\n",
      " [ 0.16602918 -0.12460276]\n",
      " [ 0.13970452  0.16517342]\n",
      " [ 0.39365041 -0.15571591]\n",
      " [-0.01187318  0.14028941]\n",
      " [ 0.45556213 -0.18143672]\n",
      " [ 0.47200236 -0.0370069 ]\n",
      " [ 0.46193809 -0.62754484]\n",
      " [ 0.59904631 -0.30985916]\n",
      " [ 0.06796716 -0.12907523]\n",
      " [ 0.29034591  0.08403566]\n",
      " [ 0.09705448  0.06770071]\n",
      " [ 0.42714362 -0.05975276]\n",
      " [ 0.46552684 -0.31449853]\n",
      " [ 0.28082104 -0.32626936]\n",
      " [ 0.30094166 -0.48625891]\n",
      " [ 0.58660058 -0.45810805]\n",
      " [ 0.70768725 -0.43585117]\n",
      " [ 0.09297226 -0.14412754]\n",
      " [ 0.40653227 -0.08697192]\n",
      " [ 0.67556432 -0.48748655]\n",
      " [ 0.4215637  -0.55811078]\n",
      " [ 0.40345039  0.05037991]\n",
      " [ 0.44465062 -0.46202566]\n",
      " [-0.12918871 -0.00828576]\n",
      " [ 0.28982974 -0.49226184]\n",
      " [ 0.64087936 -0.32300693]\n",
      " [ 0.39165099 -0.28471044]\n",
      " [ 0.65447896 -0.36908522]\n",
      " [ 0.23064261 -0.42670117]\n",
      " [ 0.36488391 -0.29384459]\n",
      " [ 0.4280767  -0.11185274]\n",
      " [ 0.46158797 -0.39816656]\n",
      " [ 0.47445331 -0.67844196]\n",
      " [ 0.29550749 -0.14862769]\n",
      " [ 0.24589021 -0.71188451]\n",
      " [ 0.23110451 -0.54986686]\n",
      " [ 0.21648756 -0.40845435]\n",
      " [ 0.00235076  0.2307391 ]\n",
      " [ 0.33760685 -0.24691168]\n",
      " [ 0.4250715  -0.08902427]\n",
      " [ 0.2320735   0.07249508]\n",
      " [ 0.09938403 -0.34536016]\n",
      " [ 0.24193321  0.05933812]\n",
      " [ 0.48229945 -0.11633101]\n",
      " [ 0.17722446 -0.26405575]\n",
      " [ 0.65153328 -0.35308897]\n",
      " [ 0.66270597 -0.76777898]\n",
      " [ 0.28009251 -0.33332374]]\n",
      "[[ 0.17562138 -0.17562138]\n",
      " [ 0.11513419 -0.11513419]\n",
      " [ 0.46325811 -0.46325811]\n",
      " [ 0.30946536 -0.30946536]\n",
      " [ 0.29168514 -0.29168514]\n",
      " [ 0.14898574 -0.14898574]\n",
      " [ 0.45129206 -0.45129206]\n",
      " [ 0.19281202 -0.19281202]\n",
      " [ 0.25186436 -0.25186436]\n",
      " [ 0.07697861 -0.07697861]\n",
      " [ 0.08930626 -0.08930626]\n",
      " [ 0.21432148 -0.21432148]\n",
      " [ 0.16672085 -0.16672085]\n",
      " [ 0.19207466 -0.19207466]\n",
      " [ 0.23869326 -0.23869326]\n",
      " [ 0.21994041 -0.21994041]\n",
      " [ 0.08221411 -0.08221411]\n",
      " [ 0.1930163  -0.1930163 ]\n",
      " [ 0.0610265  -0.0610265 ]\n",
      " [ 0.2642564  -0.2642564 ]\n",
      " [ 0.13539454 -0.13539454]\n",
      " [ 0.18273957 -0.18273957]\n",
      " [ 0.43246908 -0.43246908]\n",
      " [ 0.42716707 -0.42716707]\n",
      " [ 0.19499425 -0.19499425]\n",
      " [ 0.11214414 -0.11214414]\n",
      " [ 0.35205731 -0.35205731]\n",
      " [ 0.36851777 -0.36851777]\n",
      " [ 0.2082339  -0.2082339 ]\n",
      " [ 0.22921692 -0.22921692]\n",
      " [ 0.23281693 -0.23281693]\n",
      " [ 0.36001271 -0.36001271]\n",
      " [ 0.197569   -0.197569  ]\n",
      " [ 0.22870722 -0.22870722]\n",
      " [ 0.25635058 -0.25635058]\n",
      " [ 0.22866142 -0.22866142]\n",
      " [ 0.25959187 -0.25959187]\n",
      " [ 0.23471907 -0.23471907]\n",
      " [ 0.0457702  -0.0457702 ]\n",
      " [ 0.27336073 -0.27336073]\n",
      " [ 0.11466185 -0.11466185]\n",
      " [ 0.1606031  -0.1606031 ]\n",
      " [ 0.31395353 -0.31395353]\n",
      " [ 0.11725699 -0.11725699]\n",
      " [ 0.12611632 -0.12611632]\n",
      " [ 0.08969026 -0.08969026]\n",
      " [ 0.12858971 -0.12858971]\n",
      " [ 0.39031729 -0.39031729]\n",
      " [ 0.21574177 -0.21574177]\n",
      " [ 0.20448077 -0.20448077]\n",
      " [ 0.23964713 -0.23964713]\n",
      " [ 0.44234345 -0.44234345]\n",
      " [ 0.28135988 -0.28135988]\n",
      " [ 0.03928129 -0.03928129]\n",
      " [ 0.07037807 -0.07037807]\n",
      " [ 0.50041356 -0.50041356]\n",
      " [ 0.09265345 -0.09265345]\n",
      " [ 0.22589588 -0.22589588]\n",
      " [ 0.03165233 -0.03165233]\n",
      " [ 0.28053438 -0.28053438]\n",
      " [ 0.1472515  -0.1472515 ]\n",
      " [ 0.03305135 -0.03305135]\n",
      " [ 0.30198844 -0.30198844]\n",
      " [ 0.2069553  -0.2069553 ]\n",
      " [ 0.10760839 -0.10760839]\n",
      " [ 0.29140412 -0.29140412]\n",
      " [ 0.20827469 -0.20827469]\n",
      " [ 0.22720742 -0.22720742]\n",
      " [ 0.2784397  -0.2784397 ]\n",
      " [ 0.27055124 -0.27055124]\n",
      " [ 0.22449323 -0.22449323]\n",
      " [ 0.00158135 -0.00158135]\n",
      " [-0.0615988   0.0615988 ]\n",
      " [ 0.2503366  -0.2503366 ]\n",
      " [ 0.01065639 -0.01065639]\n",
      " [ 0.47901883 -0.47901883]\n",
      " [ 0.41884213 -0.41884213]\n",
      " [ 0.25946945 -0.25946945]\n",
      " [ 0.236135   -0.236135  ]\n",
      " [-0.05213956  0.05213956]\n",
      " [ 0.26443466 -0.26443466]\n",
      " [ 0.0930538  -0.0930538 ]\n",
      " [ 0.05968336 -0.05968336]\n",
      " [ 0.24877179 -0.24877179]\n",
      " [ 0.26448398 -0.26448398]\n",
      " [ 0.21907432 -0.21907432]\n",
      " [ 0.12696558 -0.12696558]\n",
      " [ 0.20805209 -0.20805209]\n",
      " [ 0.0058021  -0.0058021 ]\n",
      " [ 0.25472967 -0.25472967]\n",
      " [ 0.44505271 -0.44505271]\n",
      " [ 0.27847919 -0.27847919]\n",
      " [ 0.29834069 -0.29834069]\n",
      " [ 0.32922981 -0.32922981]\n",
      " [ 0.31211275 -0.31211275]\n",
      " [ 0.22239854 -0.22239854]\n",
      " [ 0.18599107 -0.18599107]\n",
      " [ 0.36912262 -0.36912262]\n",
      " [ 0.27012305 -0.27012305]\n",
      " [ 0.37772161 -0.37772161]\n",
      " [ 0.46165558 -0.46165558]\n",
      " [ 0.21902605 -0.21902605]\n",
      " [ 0.30372542 -0.30372542]\n",
      " [ 0.23574636 -0.23574636]\n",
      " [ 0.26140854 -0.26140854]\n",
      " [ 0.16250256 -0.16250256]\n",
      " [ 0.10594718 -0.10594718]\n",
      " [ 0.39703467 -0.39703467]\n",
      " [ 0.24897773 -0.24897773]\n",
      " [ 0.17542365 -0.17542365]\n",
      " [ 0.45259956 -0.45259956]\n",
      " [-0.08143008  0.08143008]\n",
      " [ 0.38158839 -0.38158839]\n",
      " [ 0.47599935 -0.47599935]\n",
      " [ 0.04906237 -0.04906237]\n",
      " [ 0.05448519 -0.05448519]\n",
      " [ 0.13631886 -0.13631886]\n",
      " [ 0.139871   -0.139871  ]\n",
      " [ 0.1074852  -0.1074852 ]\n",
      " [ 0.1978452  -0.1978452 ]\n",
      " [ 0.31228004 -0.31228004]\n",
      " [ 0.19311888 -0.19311888]\n",
      " [ 0.23737445 -0.23737445]\n",
      " [ 0.29435756 -0.29435756]\n",
      " [ 0.14012896 -0.14012896]\n",
      " [ 0.22488483 -0.22488483]\n",
      " [ 0.22670118 -0.22670118]\n",
      " [ 0.18587662 -0.18587662]\n",
      " [ 0.13501898 -0.13501898]\n",
      " [ 0.24335256 -0.24335256]\n",
      " [ 0.28008162 -0.28008162]\n",
      " [ 0.44698825 -0.44698825]\n",
      " [ 0.21943643 -0.21943643]\n",
      " [ 0.21602344 -0.21602344]\n",
      " [ 0.27299225 -0.27299225]\n",
      " [ 0.20294896 -0.20294896]\n",
      " [ 0.39995441 -0.39995441]\n",
      " [ 0.22536348 -0.22536348]\n",
      " [ 0.32963647 -0.32963647]\n",
      " [ 0.14931184 -0.14931184]\n",
      " [ 0.27307451 -0.27307451]\n",
      " [ 0.14456858 -0.14456858]\n",
      " [ 0.40908246 -0.40908246]\n",
      " [ 0.20475598 -0.20475598]\n",
      " [ 0.37677114 -0.37677114]\n",
      " [ 0.44299578 -0.44299578]\n",
      " [ 0.180849   -0.180849  ]\n",
      " [ 0.47858104 -0.47858104]\n",
      " [ 0.12237016 -0.12237016]\n",
      " [ 0.23059362 -0.23059362]\n",
      " [ 0.23384466 -0.23384466]\n",
      " [ 0.25972811 -0.25972811]\n",
      " [ 0.23172355 -0.23172355]\n",
      " [ 0.25632454 -0.25632454]\n",
      " [ 0.2301863  -0.2301863 ]\n",
      " [ 0.17517143 -0.17517143]\n",
      " [ 0.31586555 -0.31586555]\n",
      " [ 0.19825527 -0.19825527]\n",
      " [ 0.24738367 -0.24738367]\n",
      " [ 0.47362846 -0.47362846]\n",
      " [ 0.1708726  -0.1708726 ]\n",
      " [ 0.26230768 -0.26230768]\n",
      " [ 0.19130982 -0.19130982]\n",
      " [-0.05541658  0.05541658]\n",
      " [ 0.15564912 -0.15564912]\n",
      " [ 0.0722859  -0.0722859 ]\n",
      " [ 0.28938153 -0.28938153]\n",
      " [ 0.26915549 -0.26915549]\n",
      " [ 0.26186819 -0.26186819]\n",
      " [ 0.22275926 -0.22275926]\n",
      " [ 0.22780142 -0.22780142]\n",
      " [ 0.37098789 -0.37098789]\n",
      " [ 0.26160996 -0.26160996]\n",
      " [ 0.25652501 -0.25652501]\n",
      " [ 0.14725099 -0.14725099]\n",
      " [ 0.18727224 -0.18727224]\n",
      " [ 0.12553105 -0.12553105]\n",
      " [ 0.3638699  -0.3638699 ]\n",
      " [ 0.22295262 -0.22295262]\n",
      " [ 0.42808406 -0.42808406]\n",
      " [ 0.26646475 -0.26646475]\n",
      " [ 0.13246275 -0.13246275]\n",
      " [ 0.21177313 -0.21177313]\n",
      " [ 0.33503034 -0.33503034]\n",
      " [ 0.33174295 -0.33174295]\n",
      " [ 0.24575012 -0.24575012]\n",
      " [ 0.20785694 -0.20785694]\n",
      " [ 0.24705672 -0.24705672]\n",
      " [ 0.26313063 -0.26313063]\n",
      " [ 0.03382767 -0.03382767]\n",
      " [ 0.27289314 -0.27289314]\n",
      " [ 0.24527568 -0.24527568]\n",
      " [ 0.47175764 -0.47175764]\n",
      " [ 0.26170125 -0.26170125]\n",
      " [ 0.26867952 -0.26867952]\n",
      " [ 0.01032721 -0.01032721]\n",
      " [ 0.39960602 -0.39960602]\n",
      " [ 0.31133887 -0.31133887]\n",
      " [ 0.39756507 -0.39756507]\n",
      " [ 0.19531886 -0.19531886]\n",
      " [ 0.16924814 -0.16924814]\n",
      " [ 0.23690323 -0.23690323]\n",
      " [ 0.34402086 -0.34402086]\n",
      " [ 0.38785116 -0.38785116]\n",
      " [ 0.27816033 -0.27816033]\n",
      " [ 0.17293131 -0.17293131]\n",
      " [ 0.19229347 -0.19229347]\n",
      " [ 0.49584252 -0.49584252]\n",
      " [ 0.2639251  -0.2639251 ]\n",
      " [ 0.14515091 -0.14515091]\n",
      " [ 0.23620734 -0.23620734]\n",
      " [ 0.2634591  -0.2634591 ]\n",
      " [ 0.23060539 -0.23060539]\n",
      " [ 0.36803116 -0.36803116]\n",
      " [ 0.24625037 -0.24625037]\n",
      " [ 0.0353612  -0.0353612 ]\n",
      " [ 0.23553927 -0.23553927]\n",
      " [ 0.2517206  -0.2517206 ]\n",
      " [ 0.24456924 -0.24456924]\n",
      " [ 0.45539558 -0.45539558]\n",
      " [ 0.38730859 -0.38730859]\n",
      " [ 0.4988643  -0.4988643 ]\n",
      " [ 0.16709877 -0.16709877]\n",
      " [ 0.4629206  -0.4629206 ]\n",
      " [ 0.23721086 -0.23721086]\n",
      " [ 0.44386142 -0.44386142]\n",
      " [ 0.33347714 -0.33347714]\n",
      " [ 0.16243584 -0.16243584]\n",
      " [ 0.14362736 -0.14362736]\n",
      " [-0.00725741  0.00725741]\n",
      " [ 0.46099237 -0.46099237]\n",
      " [ 0.2434976  -0.2434976 ]\n",
      " [ 0.37214275 -0.37214275]\n",
      " [ 0.19449032 -0.19449032]\n",
      " [ 0.21977494 -0.21977494]\n",
      " [ 0.26079989 -0.26079989]\n",
      " [ 0.16153339 -0.16153339]\n",
      " [ 0.27314799 -0.27314799]\n",
      " [ 0.35653047 -0.35653047]\n",
      " [ 0.24739517 -0.24739517]]\n",
      "0.12655288576705317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# step 3. evaluate the model\n",
    "alpha = torch.matmul(X_train, alpha_matrix)\n",
    "mu = torch.matmul(X_train, mu_matrix)\n",
    "sd = torch.abs(torch.matmul(torch.abs(X_train), sd_matrix))\n",
    "pi = torch.softmax(alpha, dim=1)\n",
    "\n",
    "# calculate the loss\n",
    "loss = WDL(y_train, q_vec, mu, sd, pi)\n",
    "# calculate the difference between estimators and real values\n",
    "print((mu - mu_true).detach().numpy())\n",
    "print((sd - sd_true).detach().numpy())\n",
    "print((pi - pi_true).detach().numpy())\n",
    "print(loss.item())\n",
    "print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "201b5660",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1710302979.py, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [10]\u001b[0;36m\u001b[0m\n\u001b[0;31m    Displaying WDL_example.txt.\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# I forgot its purpose\n",
    "\"\"\"optimizer.param_groups[0]['lr'] = 0.5\n",
    "for k in range(500):\n",
    "    alpha = torch.matmul(X_train[:, 2:3], alpha_matrix)\n",
    "    mu = torch.matmul(X_train[:, [0, 4, 6]], mu_matrix)\n",
    "    sd = torch.abs(torch.matmul(torch.abs(X_train[:, [0, 1, 6]]), sd_matrix))\n",
    "\n",
    "    alpha = torch.matmul(X_train, alpha_matrix)\n",
    "    mu = torch.matmul(X_train, mu_matrix)\n",
    "    sd = torch.abs(torch.matmul(torch.abs(X_train), sd_matrix))\n",
    "\n",
    "    pi = torch.softmax(alpha, dim=1)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = WDL(y_train, q_vec, mu, sd, pi)\n",
    "    print(k, loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"alpha = torch.matmul(X_train[:, 2:3], alpha_matrix)\n",
    "mu = torch.matmul(X_train[:, [0, 4, 6]], mu_matrix)\n",
    "sd = torch.abs(torch.matmul(torch.abs(X_train[:, [0, 1, 6]]), sd_matrix))\"\"\"\n",
    "# WDL_example.txt\n",
    "# Displaying WDL_example.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7738a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
