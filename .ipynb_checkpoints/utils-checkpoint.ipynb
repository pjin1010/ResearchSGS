{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d773a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pyqg\n",
    "import operator\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "class Parameterization(pyqg.Parameterization):\n",
    "    \"\"\"Helper class for defining parameterizations. This extends the normal\n",
    "    pyqg parameterization framework to handle prediction of either subgrid\n",
    "    forcings or fluxes, as well as to apply to either pyqg.Models or\n",
    "    xarray.Datasets.\"\"\"\n",
    "    \n",
    "    @property\n",
    "    def targets(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def predict(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    @property\n",
    "    def nx(self):\n",
    "        return 64 # Future work should generalize this.\n",
    "\n",
    "    @property\n",
    "    def parameterization_type(self):\n",
    "        if any(q in self.targets[0] for q in ['q_forcing', 'q_subgrid']):\n",
    "            return 'q_parameterization'\n",
    "        else:\n",
    "            return 'uv_parameterization'\n",
    "\n",
    "    def __call__(self, m):\n",
    "        def arr(x):\n",
    "            if isinstance(x, xr.DataArray): x = x.data\n",
    "            return x.astype(m.q.dtype)\n",
    "\n",
    "        preds = self.predict(m)\n",
    "        keys = list(sorted(preds.keys()))\n",
    "        assert keys == self.targets\n",
    "        if len(keys) == 1:\n",
    "            return arr(preds[keys[0]])\n",
    "        elif keys == ['uq_subgrid_flux', 'vq_subgrid_flux']:\n",
    "            ex = FeatureExtractor(m)\n",
    "            return arr(ex.ddx(preds['uq_subgrid_flux']) + ex.ddy(preds['vq_subgrid_flux']))\n",
    "        elif 'uu_subgrid_flux' in keys and len(keys) == 3:\n",
    "            ex = FeatureExtractor(m)\n",
    "            return (arr(ex.ddx(preds['uu_subgrid_flux']) + ex.ddy(preds['uv_subgrid_flux'])),\n",
    "                    arr(ex.ddx(preds['uv_subgrid_flux']) + ex.ddy(preds['vv_subgrid_flux'])))\n",
    "        else:\n",
    "            return tuple(arr(preds[k]) for k in keys)\n",
    "\n",
    "    def run_online(self, sampling_freq=1000, **kw):\n",
    "        \"\"\"Run a parameterized pyqg.QGModel, saving snapshots every 1000h.\"\"\"\n",
    "        \n",
    "        # Initialize a pyqg model with this parameterization\n",
    "        params = dict(kw)\n",
    "        params[self.parameterization_type] = self\n",
    "        params['nx'] = self.nx\n",
    "        m = pyqg.QGModel(**params)\n",
    "\n",
    "        # Run it, saving snapshots\n",
    "        snapshots = []\n",
    "        while m.t < m.tmax:\n",
    "            if m.tc % sampling_freq == 0:\n",
    "                snapshots.append(m.to_dataset().copy(deep=True))\n",
    "            m._step_forward()\n",
    "\n",
    "        ds = xr.concat(snapshots, dim='time')\n",
    "        \n",
    "        # Diagnostics get dropped by this procedure since they're only present for\n",
    "        # part of the timeseries; resolve this by saving the most recent\n",
    "        # diagnostics (they're already time-averaged so this is ok)\n",
    "        for k,v in snapshots[-1].variables.items():\n",
    "            if k not in ds:\n",
    "                ds[k] = v.isel(time=-1)\n",
    "\n",
    "        # Drop complex variables since they're redundant and can't be saved\n",
    "        complex_vars = [k for k,v in ds.variables.items() if np.iscomplexobj(v)]\n",
    "        ds = ds.drop_vars(complex_vars)\n",
    "\n",
    "        return ds\n",
    "\n",
    "    def test_offline(self, dataset):\n",
    "        \"\"\"Evaluate the parameterization on an offline dataset,\n",
    "        computing a variety of metrics.\"\"\"\n",
    "        \n",
    "        test = dataset[self.targets]\n",
    "        \n",
    "        for key, val in self.predict(dataset).items():\n",
    "            truth = test[key]\n",
    "            test[f\"{key}_predictions\"] = truth*0 + val\n",
    "            preds = test[f\"{key}_predictions\"]\n",
    "            error = (truth - preds)**2\n",
    "\n",
    "            true_centered = (truth - truth.mean())\n",
    "            pred_centered = (preds - preds.mean())\n",
    "            true_var = true_centered**2\n",
    "            pred_var = pred_centered**2\n",
    "            true_pred_cov = true_centered * pred_centered\n",
    "\n",
    "            def dims_except(*dims):\n",
    "                return [d for d in test[key].dims if d not in dims]\n",
    "            \n",
    "            time = dims_except('x','y','lev')\n",
    "            space = dims_except('time','lev')\n",
    "            both = dims_except('lev')\n",
    "\n",
    "            test[f\"{key}_spatial_mse\"] = error.mean(dim=time)\n",
    "            test[f\"{key}_temporal_mse\"] = error.mean(dim=space)\n",
    "            test[f\"{key}_mse\"] = error.mean(dim=both)\n",
    "\n",
    "            test[f\"{key}_spatial_skill\"] = 1 - test[f\"{key}_spatial_mse\"] / true_var.mean(dim=time)\n",
    "            test[f\"{key}_temporal_skill\"] = 1 - test[f\"{key}_temporal_mse\"] / true_var.mean(dim=space)\n",
    "            test[f\"{key}_skill\"] = 1 - test[f\"{key}_mse\"] / true_var.mean(dim=both)\n",
    "\n",
    "            test[f\"{key}_spatial_correlation\"] = xr.corr(truth, preds, dim=time)\n",
    "            test[f\"{key}_temporal_correlation\"] = xr.corr(truth, preds, dim=space)\n",
    "            test[f\"{key}_correlation\"] = xr.corr(truth, preds, dim=both)\n",
    "\n",
    "        for metric in ['correlation', 'mse', 'skill']:\n",
    "            test[metric] = sum(\n",
    "                test[f\"{key}_{metric}\"] for key in self.targets\n",
    "            ) / len(self.targets)\n",
    "\n",
    "        return test\n",
    "\n",
    "class FeatureExtractor:\n",
    "    \"\"\"Helper class for taking spatial derivatives and translating string\n",
    "    expressions into data. Works with either pyqg.Model or xarray.Dataset.\"\"\"\n",
    "    \n",
    "    def __call__(self, feature_or_features, flat=False):\n",
    "        arr = lambda x: x.data if isinstance(x, xr.DataArray) else x\n",
    "        if isinstance(feature_or_features, str):\n",
    "            res = arr(self.extract_feature(feature_or_features))\n",
    "            if flat: res = res.reshape(-1)\n",
    "\n",
    "        else:\n",
    "            res = np.array([arr(self.extract_feature(f)) for f in feature_or_features])\n",
    "            if flat: res = res.reshape(len(feature_or_features), -1).T\n",
    "        return res\n",
    "\n",
    "    def __init__(self, model_or_dataset):\n",
    "        self.m = model_or_dataset\n",
    "        self.cache = {}\n",
    "        \n",
    "        if hasattr(self.m, '_ik'):\n",
    "            self.ik, self.il = np.meshgrid(self.m._ik, self.m._il)\n",
    "        elif hasattr(self.m, 'fft'):\n",
    "            self.ik = 1j * self.m.k\n",
    "            self.il = 1j * self.m.l\n",
    "        else:\n",
    "            k, l = np.meshgrid(self.m.k, self.m.l)\n",
    "            self.ik = 1j * k\n",
    "            self.il = 1j * l\n",
    "\n",
    "        self.nx = self.ik.shape[0]\n",
    "        self.wv2 = self.ik**2 + self.il**2\n",
    "\n",
    "    # Helpers for taking FFTs / deciding if we need to\n",
    "    def fft(self, x):\n",
    "        try:\n",
    "            return self.m.fft(x)\n",
    "        except:\n",
    "            # Convert to data array\n",
    "            dims = [dict(y='l',x='k').get(d,d) for d in self['q'].dims]\n",
    "            coords = dict([(d, self[d]) for d in dims])\n",
    "            return xr.DataArray(np.fft.rfftn(x, axes=(-2,-1)), dims=dims, coords=coords)\n",
    "\n",
    "    def ifft(self, x):\n",
    "        try:\n",
    "            return self.m.ifft(x)\n",
    "        except:\n",
    "            return self['q']*0 + np.fft.irfftn(x, axes=(-2,-1))\n",
    "    \n",
    "    def is_real(self, arr):\n",
    "        return len(set(arr.shape[-2:])) == 1\n",
    "    \n",
    "    def real(self, arr):\n",
    "        arr = self[arr]\n",
    "        if isinstance(arr, float): return arr\n",
    "        if self.is_real(arr): return arr\n",
    "        return self.ifft(arr)\n",
    "    \n",
    "    def compl(self, arr):\n",
    "        arr = self[arr]\n",
    "        if isinstance(arr, float): return arr\n",
    "        if self.is_real(arr): return self.fft(arr)\n",
    "        return arr\n",
    "\n",
    "    # Spectral derivatrives\n",
    "    def ddxh(self, f): return self.ik * self.compl(f)\n",
    "    def ddyh(self, f): return self.il * self.compl(f)\n",
    "    def divh(self, x, y): return self.ddxh(x) + self.ddyh(y)\n",
    "    def curlh(self, x, y): return self.ddxh(y) - self.ddyh(x)\n",
    "    def laplacianh(self, x): return self.wv2 * self.compl(x)\n",
    "    def advectedh(self, x_):\n",
    "        x = self.real(x_)\n",
    "        return self.ddxh(x * self.m.ufull) + self.ddyh(x * self.m.vfull)\n",
    "\n",
    "    # Real counterparts\n",
    "    def ddx(self, f): return self.real(self.ddxh(f))\n",
    "    def ddy(self, f): return self.real(self.ddyh(f))\n",
    "    def laplacian(self, x): return self.real(self.laplacianh(x))\n",
    "    def advected(self, x): return self.real(self.advectedh(x))\n",
    "    def curl(self, x, y): return self.real(self.curlh(x,y))\n",
    "    def div(self, x, y): return self.real(self.divh(x,y))\n",
    "\n",
    "    # Main function: interpreting a string as a feature\n",
    "    def extract_feature(self, feature):\n",
    "        \"\"\"Evaluate a string feature, e.g. laplacian(advected(curl(u,v))).\"\"\"\n",
    "        \n",
    "        # Helper to recurse on each side of an arity-2 expression\n",
    "        def extract_pair(s):\n",
    "            depth = 0\n",
    "            for i, char in enumerate(s):\n",
    "                if char == \"(\":\n",
    "                    depth += 1\n",
    "                elif char == \")\":\n",
    "                    depth -= 1\n",
    "                elif char == \",\" and depth == 0:\n",
    "                    return self.extract_feature(s[:i].strip()), self.extract_feature(s[i+1:].strip())\n",
    "            raise ValueError(f\"string {s} is not a comma-separated pair\")\n",
    "\n",
    "        real_or_spectral = lambda arr: arr + [a+'h' for a in arr]\n",
    "            \n",
    "        if not self.extracted(feature):\n",
    "            # Check if the feature looks like \"function(expr1, expr2)\"\n",
    "            # (better would be to write a grammar + use a parser,\n",
    "            # but this is a very simple DSL)\n",
    "            match = re.search(f\"^([a-z]+)\\((.*)\\)$\", feature)\n",
    "            if match:\n",
    "                op, inner = match.group(1), match.group(2)\n",
    "                if op in ['mul', 'add', 'sub', 'pow']:\n",
    "                    self.cache[feature] = getattr(operator, op)(*extract_pair(inner))\n",
    "                elif op in ['neg', 'abs']:\n",
    "                    self.cache[feature] = getattr(operator, op)(self.extract_feature(inner))\n",
    "                elif op in real_or_spectral(['div', 'curl']):\n",
    "                    self.cache[feature] = getattr(self, op)(*extract_pair(inner))\n",
    "                elif op in real_or_spectral(['ddx', 'ddy', 'advected', 'laplacian']):\n",
    "                    self.cache[feature] = getattr(self, op)(self.extract_feature(inner))\n",
    "                else:\n",
    "                    raise ValueError(f\"could not interpret {feature}\")\n",
    "            elif re.search(f\"^[\\-\\d\\.]+$\", feature):\n",
    "                # ensure numbers still work\n",
    "                return float(feature)\n",
    "            elif feature == 'streamfunction':\n",
    "                # hack to make streamfunctions work in both datasets & pyqg.Models\n",
    "                self.cache[feature] = self.ifft(self['ph'])\n",
    "            else:\n",
    "                raise ValueError(f\"could not interpret {feature}\")\n",
    "\n",
    "        return self[feature]\n",
    "\n",
    "    def extracted(self, key):\n",
    "        return key in self.cache or hasattr(self.m, key)\n",
    "\n",
    "    # A bit of additional hackery to allow for the reading of features or properties\n",
    "    def __getitem__(self, q):\n",
    "        if isinstance(q, str):\n",
    "            if q in self.cache:\n",
    "                return self.cache[q]\n",
    "            elif re.search(f\"^[\\-\\d\\.]+$\", q):\n",
    "                return float(q)\n",
    "            else:\n",
    "                return getattr(self.m, q)\n",
    "        elif any([isinstance(q, kls) for kls in [xr.DataArray, np.ndarray, int, float]]):\n",
    "            return q\n",
    "        else:\n",
    "            raise KeyError(q)\n",
    "\n",
    "def energy_budget_term(model, term):\n",
    "    val = model[term]\n",
    "    if 'paramspec_' + term in model:\n",
    "        val += model['paramspec_' + term]\n",
    "    return val.sum('l')\n",
    "\n",
    "def energy_budget_figure(models, skip=0):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure(figsize=(12,5))\n",
    "    vmax = 0\n",
    "    for i,term in enumerate(['KEflux','APEflux','APEgenspec','KEfrictionspec']):\n",
    "        plt.subplot(1,4,i+1,title=term)\n",
    "        plt.axhline(0,color='gray', ls='--')\n",
    "        \n",
    "        for model, label in models:\n",
    "            spec = energy_budget_term(model, term)\n",
    "            plt.semilogx(model.k[skip:], spec[skip:],\n",
    "                         label=label, lw=3, ls=('--' if '+' in label else '-'))\n",
    "            vmax = max(vmax, spec[skip:].max())\n",
    "        plt.grid(which='both',alpha=0.25)\n",
    "        if i == 0: plt.ylabel(\"Energy transfer $[m^2 s^{-3}]$\")\n",
    "        else: plt.gca().set_yticklabels([])\n",
    "        if i == 3: plt.legend()\n",
    "        plt.xlabel(\"Zonal wavenumber $[m^{-1}]$\")\n",
    "    for ax in fig.axes:\n",
    "        ax.set_ylim(-vmax, vmax)\n",
    "    plt.tight_layout()\n",
    "    return fig\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
